Flavor: r-devel-windows-ix86+x86_64
Check: CRAN incoming feasibility, Result: FAIL
  

Flavor: r-devel-linux-x86_64-debian-gcc
Check: CRAN incoming feasibility, Result: NOTE
  Maintainer: '"Mu Sigma, Inc." <ird.experiencelab@mu-sigma.com>'
  
  New submission
  
  Package was archived on CRAN
  
  Possibly mis-spelled words in DESCRIPTION:
    Voronoi (4:34, 14:40)
  
  CRAN repository db overrides:
    X-CRAN-Comment: Archived on 2019-08-09 as check problems were not
      corrected in time.
  
  Found the following (possibly) invalid URLs:
    URL: https://github.com/thomaspernet/data_csv_r/blob/master/data/Computers.csv
      From: inst/doc/muHVT.html
      Status: 404
      Message: Not Found
  
  File 'R/muHVT-internal.R' sets .Random.seed.
  This is usually neither needed nor wanted.

Flavor: r-devel-linux-x86_64-debian-gcc
Check: top-level files, Result: NOTE
  File
    LICENSE
  is not mentioned in the DESCRIPTION file.

Flavor: r-devel-linux-x86_64-debian-gcc
Check: dependencies in R code, Result: WARNING
  '::' or ':::' imports not declared from:
    'polyclip' 'rgeos'
  'library' or 'require' call not declared from: 'ggplot2'
  'loadNamespace' or 'requireNamespace' call not declared from: 'polyclip'
  'library' or 'require' call to 'ggplot2' in package code.
    Please use :: or requireNamespace() instead.
    See section 'Suggested packages' in the 'Writing R Extensions' manual.

Flavor: r-devel-linux-x86_64-debian-gcc
Check: R code for possible problems, Result: NOTE
  DelaunayInfo : Parent_Tile_Boxes: no visible global function definition
    for 'point.in.polygon'
  DelaunayInfo: no visible global function definition for
    'point.in.polygon'
  HVT : <anonymous>: no visible global function definition for 'sd'
  HVT: no visible global function definition for 'map'
  getCentroids: no visible binding for global variable '.'
  getCentroids_for_opti: no visible binding for global variable '.'
  hvq: no visible binding for '<<-' assignment to
    'calculate_euclidean_distance_for_each_cluster'
  hvq: no visible binding for '<<-' assignment to
    'calculate_manhattan_distance_for_each_cluster'
  hvq: no visible binding for '<<-' assignment to
    'function_to_calculate_distance_metric'
  hvq: no visible binding for global variable
    'calculate_manhattan_distance_for_each_cluster'
  hvq: no visible binding for global variable
    'calculate_euclidean_distance_for_each_cluster'
  hvq: no visible binding for '<<-' assignment to
    'function_to_calculate_error_metric'
  hvq: no visible binding for global variable
    'function_to_calculate_distance_metric'
  hvq: no visible binding for global variable
    'function_to_calculate_error_metric'
  hvq: no visible binding for global variable 'Segment.Level'
  hvq: no visible binding for global variable 'Quant.Error'
  hvq: no visible binding for global variable
    'noOfCellsBelowQuantizationError'
  hvq: no visible binding for global variable 'noOfCells'
  hvtHmap: no visible binding for global variable 'Segment.Level'
  hvtHmap: no visible binding for global variable 'Segment.Parent'
  hvtHmap: no visible binding for global variable 'Segment.Child'
  hvtHmap: no visible global function definition for 'aes'
  hvtHmap: no visible binding for global variable 'cluster'
  hvtHmap: no visible binding for global variable 'child'
  hvtHmap: no visible binding for global variable 'value'
  hvtHmap: no visible global function definition for
    'scale_fill_gradientn'
  hvtHmap: no visible global function definition for 'labs'
  hvtHmap: no visible global function definition for
    'scale_colour_manual'
  hvtHmap: no visible global function definition for 'scale_size_manual'
  hvtHmap: no visible global function definition for 'geom_point'
  hvtHmap: no visible global function definition for 'element_text'
  hvtHmap: no visible global function definition for 'margin'
  hvtHmap: no visible global function definition for 'element_blank'
  hvtHmap: no visible global function definition for 'scale_x_continuous'
  hvtHmap: no visible global function definition for 'scale_y_continuous'
  plotHVT: no visible global function definition for 'aes'
  plotHVT: no visible binding for global variable 'cluster'
  plotHVT: no visible binding for global variable 'child'
  plotHVT: no visible global function definition for
    'scale_colour_manual'
  plotHVT: no visible global function definition for 'scale_size_manual'
  plotHVT: no visible global function definition for 'labs'
  plotHVT: no visible global function definition for 'scale_color_manual'
  plotHVT: no visible global function definition for 'element_text'
  plotHVT: no visible global function definition for 'margin'
  plotHVT: no visible global function definition for 'element_blank'
  plotHVT: no visible global function definition for 'theme'
  plotHVT: no visible global function definition for 'scale_x_continuous'
  plotHVT: no visible global function definition for 'scale_y_continuous'
  predictHVT : find_path: no visible binding for global variable
    'Segment.Level'
  predictHVT : find_path: no visible binding for global variable 'index'
  predictHVT: no visible binding for global variable 'Segment.Level'
  predictHVT: no visible binding for global variable 'Segment.Parent'
  predictHVT: no visible binding for global variable 'Segment.Child'
  predictHVT: no visible global function definition for 'group_by'
  predictHVT: no visible global function definition for 'summarise_all'
  predictHVT: no visible global function definition for 'funs'
  predictHVT: no visible global function definition for 'theme'
  predictHVT: no visible global function definition for 'element_text'
  predictHVT: no visible global function definition for 'margin'
  predictHVT: no visible global function definition for 'element_blank'
  predictHVT: no visible global function definition for
    'scale_x_continuous'
  predictHVT: no visible global function definition for
    'scale_y_continuous'
  Undefined global functions or variables:
    . Quant.Error Segment.Child Segment.Level Segment.Parent aes
    calculate_euclidean_distance_for_each_cluster
    calculate_manhattan_distance_for_each_cluster child cluster
    element_blank element_text function_to_calculate_distance_metric
    function_to_calculate_error_metric funs geom_point group_by index
    labs map margin noOfCells noOfCellsBelowQuantizationError
    point.in.polygon scale_color_manual scale_colour_manual
    scale_fill_gradientn scale_size_manual scale_x_continuous
    scale_y_continuous sd summarise_all theme value
  Consider adding
    importFrom("stats", "sd")
  to your NAMESPACE file.

Flavor: r-devel-linux-x86_64-debian-gcc
Check: for code/documentation mismatches, Result: WARNING
  Codoc mismatches from documentation object 'HVT':
  HVT
    Code: function(dataset, nclust = 15, depth = 3, quant.err = 0.2,
                   projection.scale = 10, normalize = TRUE,
                   distance_metric = c("L1_Norm", "L2_Norm"),
                   error_metric = c("mean", "max"))
    Docs: function(dataset, nclust, depth, quant.err, projection.scale,
                   normalize = T, distance_metric = c("L1_Norm",
                   "L2_Norm"), error_metric = c("mean", "max"))
    Mismatches in argument default values (first 3):
      Name: 'nclust' Code: 15 Docs: 
      Name: 'depth' Code: 3 Docs: 
      Name: 'quant.err' Code: 0.2 Docs: 
  
  Codoc mismatches from documentation object 'hvq':
  hvq
    Code: function(x, nclust = 15, depth = 3, quant.err = 0.2, algorithm
                   = "Hartigan-Wong", distance_metric = c("L1_Norm",
                   "L2_Norm"), error_metric = c("mean", "max"))
    Docs: function(x, nclust = 3, depth = 3, quant.err = 10, algorithm =
                   c("Hartigan-Wong", "Lloyd", "Forgy", "MacQueen"),
                   distance_metric = c("L1_Norm", "L2_Norm"),
                   error_metric = c("mean", "max"))
    Mismatches in argument default values:
      Name: 'nclust' Code: 15 Docs: 3
      Name: 'quant.err' Code: 0.2 Docs: 10
      Name: 'algorithm' Code: "Hartigan-Wong" Docs: c("Hartigan-Wong", "Lloyd", "Forgy", "MacQueen")
  
  Codoc mismatches from documentation object 'hvtHmap':
  hvtHmap
    Code: function(hvt.results, dataset, child.level, hmap.cols,
                   color.vec = NULL, line.width = NULL, centroid.size =
                   3, pch = 21, palette.color = 6, previous_level_heatmap
                   = TRUE, show.points = FALSE, asp = 1, ask = TRUE,
                   tess.label = NULL, quant.error.hmap = NULL,
                   nclust.hmap = NULL, label.size = 0.5, ...)
    Docs: function(hvt.results, dataset, child.level, hmap.cols,
                   color.vec = NULL, line.width = NULL, centroid.size =
                   3, pch = 21, palette.color = 6, previous_level_heatmap
                   = T, show.points = F, asp = 1, ask = T, tess.label =
                   NULL, label.size = 0.5, ...)
    Argument names in code not in docs:
      quant.error.hmap nclust.hmap
    Mismatches in argument names:
      Position: 15 Code: quant.error.hmap Docs: label.size
      Position: 16 Code: nclust.hmap Docs: ...
    Mismatches in argument default values:
      Name: 'previous_level_heatmap' Code: TRUE Docs: T
      Name: 'show.points' Code: FALSE Docs: F
      Name: 'ask' Code: TRUE Docs: T
  
  Codoc mismatches from documentation object 'plotHVT':
  plotHVT
    Code: function(hvt.results, line.width, color.vec, pch1 = 21,
                   centroid.size = 3, title = NULL, maxDepth = NULL)
    Docs: function(hvt.results, line.width, color.vec, pch1 = 21,
                   centroid.size = 3, title = NULL)
    Argument names in code not in docs:
      maxDepth
  
  Codoc mismatches from documentation object 'predictHVT':
  predictHVT
    Code: function(data, hvt.results, hmap.cols = NULL, child.level = 1,
                   quant.error.hmap = NULL, nclust.hmap = NULL,
                   line.width = NULL, color.vec = NULL, ...)
    Docs: function(data, hvt.results, hmap.cols = NULL, child.level = 1,
                   ...)
    Argument names in code not in docs:
      quant.error.hmap nclust.hmap line.width color.vec
    Mismatches in argument names:
      Position: 5 Code: quant.error.hmap Docs: ...

Flavor: r-devel-linux-x86_64-debian-gcc
Check: examples, Result: ERROR
  Running examples in 'muHVT-Ex.R' failed
  The error most likely occurred in:
  
  > base::assign(".ptime", proc.time(), pos = "CheckExEnv")
  > ### Name: HVT
  > ### Title: Constructing Hierarchical Voronoi Tessellations
  > ### Aliases: HVT
  > ### Keywords: hplot
  > 
  > ### ** Examples
  > 
  > data(USArrests)
  > hvt.results <- list()
  > hvt.results <- HVT(USArrests, nclust = 6, depth = 1, quant.err = 0.2, 
  +                   projection.scale = 10, normalize = TRUE)
  Loading required namespace: deldir
  Loading required namespace: Hmisc
  Loading required namespace: splancs
  Loading required namespace: conf.design
   ----------- FAILURE REPORT -------------- 
   --- failure: the condition has length > 1 ---
   --- srcref --- 
  : 
   --- package (from environment) --- 
  muHVT
   --- call from context --- 
  hvq(scaledata, nclust = nclust, depth = depth, quant.err = quant.err, 
      distance_metric = distance_metric, error_metric = error_metric)
   --- call from argument --- 
  if (distance_metric == "L1_Norm") {
      function_to_calculate_distance_metric <<- calculate_manhattan_distance_for_each_cluster
  } else if (distance_metric == "L2_Norm") {
      function_to_calculate_distance_metric <<- calculate_euclidean_distance_for_each_cluster
  } else {
      stop("distance_metric must be L1_Norm (Manhattan), L2_Norm(Euclidean) or custom distance function")
  }
   --- R stacktrace ---
  where 1: hvq(scaledata, nclust = nclust, depth = depth, quant.err = quant.err, 
      distance_metric = distance_metric, error_metric = error_metric)
  where 2: HVT(USArrests, nclust = 6, depth = 1, quant.err = 0.2, projection.scale = 10, 
      normalize = TRUE)
  
   --- value of length: 2 type: logical ---
  [1]  TRUE FALSE
   --- function from context --- 
  function (x, nclust = 15, depth = 3, quant.err = 0.2, algorithm = "Hartigan-Wong", 
      distance_metric = c("L1_Norm", "L2_Norm"), error_metric = c("mean", 
          "max")) 
  {
      requireNamespace("dplyr")
      rescl <- list()
      resid <- list()
      resm <- list()
      resplt <- list()
      ztab3up <- list()
      ztab1 <- ztab2 <- ztabn <- NULL
      ztab11 <- ztab12 <- ztab13 <- NULL
      zdepth <- depth
      quantinit <- rep(FALSE, nclust)
      set.seed(300)
      calculate_euclidean_distance_for_each_cluster <<- function(x) {
          sqrt(rowSums(scale(x, center = TRUE, scale = FALSE)^2))/ncol(x)
      }
      calculate_manhattan_distance_for_each_cluster <<- function(x) {
          rowSums(abs(scale(x, center = TRUE, scale = FALSE)))/ncol(x)
      }
      if (distance_metric == "L1_Norm") {
          function_to_calculate_distance_metric <<- calculate_manhattan_distance_for_each_cluster
      }
      else if (distance_metric == "L2_Norm") {
          function_to_calculate_distance_metric <<- calculate_euclidean_distance_for_each_cluster
      }
      else {
          stop("distance_metric must be L1_Norm (Manhattan), L2_Norm(Euclidean) or custom distance function")
      }
      if (error_metric %in% c("mean", "max")) {
          function_to_calculate_error_metric <<- error_metric
      }
      else {
          stop("error_metric must be max,mean or custom function")
      }
      outkinit <- getCentroids(x, kout = stats::kmeans(x, nclust, 
          iter.max = 10^5, algorithm = algorithm), nclust, function_to_calculate_distance_metric, 
          function_to_calculate_error_metric)
      rescl[[1]] <- outkinit$val
      tet <- lapply(outkinit$val, row.names)
      for (k in 1:length(tet)) {
          tet[[k]] <- data.frame(tet[[k]], 1, 1, k)
      }
      names(tet) <- paste(1:length(tet))
      resid[[1]] <- tet
      resm[[1]] <- outkinit$cent
      resplt[[1]] <- unlist(outkinit$cent) > quant.err
      initclust <- outkinit$values
      if (depth > 1) {
          i <- 1
          while (i < depth) {
              ijclust <- NULL
              ijrescl <- list()
              ijresid <- list()
              ijresm <- list()
              ijresplt <- list()
              ijresnsize <- list()
              ijztab3up <- list()
              quantok <- unlist(resplt[[i]])
              j <- 1
              while (j < (nclust^i) + 1) {
                  if (quantok[j] & NROW(initclust[[j]]) > 3) {
                    z = data.frame(initclust[[j]])
                    outk <- getOptimalCentroids(z, iter.max = 10^5, 
                      algorithm = algorithm, nclust, function_to_calculate_distance_metric, 
                      function_to_calculate_error_metric, quant.err = quant.err)
                    ijrescl[[j]] <- outk$val
                    tet <- lapply(outk$val, row.names)
                    for (k in 1:length(tet)) {
                      if (!is.null(tet[[k]])) {
                        tet[[k]] <- data.frame(tet[[k]], i + 1, 
                          j, k)
                      }
                      else {
                        tet[[k]] <- data.frame(tet[[k]] <- numeric(0))
                      }
                    }
                    ijresid[[j]] <- tet
                    ijresm[[j]] <- outk$centers
                    ijresnsize[[j]] <- outk$nsize
                    ijztab3up[[j]] <- matrix(0, nrow = ncol(x), 
                      nclust)
                    ijztab3up[[j]] <- t(outk$centroid_val)
                    ijresplt[[j]] <- unlist(outk$centers) > quant.err
                    ijclust <- c(ijclust, outk$values)
                  }
                  else {
                    ijrescl[[j]] <- rep(NA, nclust)
                    ijresid[[j]] <- NULL
                    ijresm[[j]] <- rep(NA, nclust)
                    ijresnsize[[j]] <- rep(0, nclust)
                    ijztab3up[[j]] <- matrix(NA, ncol(x), nclust)
                    ijresplt[[j]] <- rep(FALSE, nclust)
                    ijclust <- c(ijclust, rep(NA, nclust))
                  }
                  ztab1 <- c(ztab1, paste(i + 1, j, 1:nclust, sep = ","))
                  ztab11 <- c(ztab11, rep(i + 1, nclust))
                  ztab12 <- c(ztab12, rep(j, nclust))
                  ztab13 <- c(ztab13, 1:nclust)
                  j <- j + 1
              }
              rescl[[i + 1]] <- ijrescl
              resid[[i + 1]] <- ijresid
              resm[[i + 1]] <- ijresm
              resplt[[i + 1]] <- ijresplt
              ztab2 <- c(ztab2, unlist(ijresnsize))
              ztab3up[[i + 1]] <- data.frame(ijztab3up)
              ztabn <- c(ztabn, unlist(ijresm))
              initclust <- ijclust
              i <- i + 1
              if (!is.element(TRUE, unlist(ijresplt))) {
                  zdepth <- i
                  i <- depth
              }
          }
          ztab <- data.frame(matrix(0, nrow = sum(nclust^(1:zdepth)), 
              ncol = (ncol(x) + 5)))
          ztab[1:nclust, 1] <- rep(1, nclust)
          ztab[1:nclust, 2] <- rep(1, nclust)
          ztab[1:nclust, 3] <- 1:nclust
          ztab[1:nclust, 4] <- unlist(outkinit$nsize)
          ztab[1:nclust, 5] <- unlist(outkinit$cent)
          ztab3upc <- matrix(0, nrow = ncol(x), nclust)
          for (a in 1:nclust) {
              for (b in 1:ncol(x)) {
                  ztab3upc[b, a] <- as.matrix(mean(outkinit$val[[a]][, 
                    b], na.rm = TRUE))
                  rownames(ztab3upc) <- colnames(x)
              }
          }
          for (l in 1:length(ztab3up)) ztab3upc <- cbind(ztab3upc, 
              ztab3up[[l]])
          ztab[(nclust + 1):sum(nclust^(1:zdepth)), 1] <- ztab11
          ztab[(nclust + 1):sum(nclust^(1:zdepth)), 2] <- ztab12
          ztab[(nclust + 1):sum(nclust^(1:zdepth)), 3] <- ztab13
          ztab[(nclust + 1):sum(nclust^(1:zdepth)), 4] <- ztab2
          ztab[, 6:ncol(ztab)] <- t(ztab3upc)
          ztab[(nclust + 1):sum(nclust^(1:zdepth)), 5] <- ztabn
          names(ztab) <- c("Segment.Level", "Segment.Parent", "Segment.Child", 
              "n", "Quant.Error", colnames(x))
      }
      else {
          ztab <- data.frame(matrix(0, nrow = nclust, ncol = (ncol(x) + 
              5)))
          ztab[, 1] <- rep(1, nclust)
          ztab[, 2] <- rep(1, nclust)
          ztab[, 3] <- 1:nclust
          ztab[, 4] <- unlist(outkinit$nsize)
          ztab[, 6:ncol(ztab)] <- t(sapply(outkinit$val, colMeans, 
              na.rm = TRUE))
          ztab[, 5] <- unlist(outkinit$cent)
          names(ztab) <- c("Segment.Level", "Segment.Parent", "Segment.Child", 
              "n", "Quant.Error", colnames(x))
      }
      compression_summary <- ztab %>% dplyr::group_by(Segment.Level) %>% 
          dplyr::summarise(noOfCells = sum(!is.na(Quant.Error)), 
              noOfCellsBelowQuantizationError = sum(Quant.Error < 
                  quant.err, na.rm = TRUE)) %>% dplyr::mutate(percentOfCellsBelowQuantizationErrorThreshold = (noOfCellsBelowQuantizationError/noOfCells))
      colnames(compression_summary)[1] <- "segmentLevel"
      if (any(is.nan(compression_summary$percentOfCellsBelowQuantizationErrorThreshold))) {
          compression_summary <- compression_summary[stats::complete.cases(compression_summary), 
              ]
      }
      ridnames <- resid
      rclnames <- rescl
      return(list(clusters = initclust, nodes.clust = rescl, idnodes = resid, 
          error.quant = resm, plt.clust = resplt, summary = ztab, 
          compression_summary = compression_summary))
  }
  <bytecode: 0x555bfaacfe10>
  <environment: namespace:muHVT>
   --- function search by body ---
  Function hvq in namespace muHVT has this body.
   ----------- END OF FAILURE REPORT -------------- 
  Error in if (distance_metric == "L1_Norm") { : 
    the condition has length > 1
  Calls: HVT -> hvq
  Execution halted

Flavor: r-devel-linux-x86_64-debian-gcc
Check: re-building of vignette outputs, Result: WARNING
  Error(s) in re-building vignettes:
    ...
  --- re-building 'muHVT.Rmd' using rmarkdown
  Quitting from lines 18-121 (muHVT.Rmd) 
  Error: processing vignette 'muHVT.Rmd' failed with diagnostics:
  trying to use CRAN without setting a mirror
  --- failed re-building 'muHVT.Rmd'
  
  SUMMARY: processing the following file failed:
    'muHVT.Rmd'
  
  Error: Vignette re-building failed.
  Execution halted
