---
title: "Collection of Functions used for Dynamic Analysis - Flow of Data over Time"
author: "Zubin Dowlaty, Pon Anureka Seenivasan, Vishwavani"
date: "`r Sys.Date()`"
fig.height: 4
fig.width: 15
output:
  rmarkdown::html_vignette:
    toc: true
    toc_depth : 3
vignette: >
  %\VignetteIndexEntry{Collection of functions used for Dynamic Analysis: Flow of Data over Time}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---



```{css, echo=FALSE}
/* CSS for floating TOC on the left side */
#TOC {
    /* float: left; */
    position: fixed;
    margin-left: -22vw;
    width: 18vw;
    height: fit-content;
    overflow-y: auto;
    padding-top: 20px;
    padding-bottom: 20px;
    background-color: #f9f9f9;
    border-right: 1px solid #ddd;
    margin-top: -13em; 
}
.main-container {
  margin-left: 222px; /* Adjust this value to match the width of the TOC + some margin */
}
body{
max-width:1200px;
width: 50%;
}
p {
text-align: justify;
}
.plotly {
  margin: auto;
  width: 100% !important; 
  height: 70vh !important;
}
.caption {
  text-align: center;
}
li {
  padding-bottom: 5px;
}
ul {
  margin-bottom: 0px !important;
}
```




```{r, warning=FALSE,message=FALSE,include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  out.width = "672px",
  out.height = "480px",
  fig.width = 7,
  fig.height = 5,
  fig.align = "center",
  fig.retina = 1,
  dpi = 150
)

# installing all required packages
list.of.packages <- c("dplyr", "kableExtra", "geozoo", "plotly", "purrr", "sp", "data.table", "gridExtra","plyr", "grid", "ggforce", "reactable", "markovchain", "reshape", "gganimate", "gapminder", "animation", "magick", "tidyr", "jpeg", "ggpubr", "stringr", "DT", "knitr", "kableExtra","htmltools", "htmlwidgets")

new.packages <-
  list.of.packages[!(list.of.packages %in% installed.packages()[, "Package"])]
if (length(new.packages))
  install.packages(new.packages, dependencies = TRUE)

# Loading the required libraries
lapply(list.of.packages, library, character.only = T)
options(expressions = 10000)
global_var <- nzchar(Sys.getenv("RUN_VIGNETTE"))
global_var <- TRUE
scrolLimit <- function(noOfRows){
  if(noOfRows<10){
    swe = paste(as.character(noOfRows*50),"px")
  }
  else{
    swe = "400px"
   }
  return(swe)
}
Table <- function(data,scroll = F, limit = NULL){
  if(!is.null(limit)){
    data <- head(data,limit)}
kable_table <- data %>% kable(escape = F,align = "c") %>% kable_styling(bootstrap_options = c("striped", "hover", "responsive"))
if(scroll == T){
kable_table <- kable_table %>% scroll_box(width = "100%", height = scrolLimit(nrow(data)))
  }
return(kable_table)
}

set.seed(240)
```

# 1. Abstract

The HVT package is a collection of R functions to facilitate building [topology preserving maps](https://users.ics.aalto.fi/jhollmen/dippa/node9.html) for rich multivariate data analysis. Tending towards a big data preponderance, a large number of rows. A collection of R functions for this typical workflow is organized below:

1.  **Data Compression**: Vector quantization (VQ), HVQ (hierarchical vector quantization) using means or medians. This step compresses the rows (long data frame) using a compression objective.

2.  **Data Projection**: Dimension projection of the compressed cells to 1D,2D or Interactive surface plot with the Sammons Non-linear Algorithm. This step creates topology preserving map (also called as [embedding](https://en.wikipedia.org/wiki/Embedding)) coordinates into the desired output dimension.

3.  **Tessellation**: Create cells required for object visualization using the Voronoi Tessellation method, package includes heatmap plots for hierarchical Voronoi tessellations (HVT). This step enables data insights, visualization, and interaction with the topology preserving map. Useful for semi-supervised tasks.

4.  **Scoring**: Scoring new data sets and recording their assignment using the map objects from the above steps, in a sequence of maps if required.

5. **Dynamic Analysis** A collection of functions designed to understand and visually represent the movement of data over time within a dynamic system, with the ability to forecast the next cell (t+1) by examining its underlying flow pattern.


# 2. Experimental setup 

The Lorenz attractor is a three-dimensional figure that is generated by a set of differential equations that model a simple chaotic dynamic system of convective flow. Lorenz Attractor arises from a simplified set of equations that describe the behavior of a system involving three variables. These variables represent the state of the system at any given time and are typically denoted by (x, y, z). The equations are as follows:

  $$ dx/dt = σ*(y-x) $$
  $$ dy/dt = x*(r -z)-y $$
  $$ dz/dt = x*y-β*z $$
where dx/dt, dy/dt, and dz/dt represent the rates of change of x, y, and z respectively over time (t). σ, r, and β are constant parameters of the system, with σ(σ = 10) controlling the rate of convection, r(r=28) controlling the difference in temperature between the convective and stable regions, and β(β = 8/3) representing the ratio of the width to the height of the convective layer. When these equations are plotted in three-dimensional space, they produce a chaotic trajectory that never repeats. The Lorenz attractor exhibits sensitive dependence on initial conditions, meaning even small differences in the initial conditions can lead to drastically different trajectories over time. This sensitivity to initial conditions is a defining characteristic of chaotic systems.


In this notebook, we will use the `Lorenz Attractor Dataset`. This dataset contains 200 thousand observations and 5 columns. The dataset can be downloaded from [here](https://www.kaggle.com/datasets/henrychibueze/lorenz-attractor-dataset)

The dataset includes the following columns:

* X: The X-coordinate of a point in the Lorenz attractor. It represents the measure of strength of the circulation of fluid in the convective flow
* Y: The Y-coordinate of a point in the Lorenz attractor. It represents the measure of the temperature of the fluid at a given point in space, but it is the horizontal temperature distribution
* Z: The Z-coordinate of a point in the Lorenz attractor. It represents the measure of the temperature of the fluid at a given point in space, but it is the vertical temperature distribution
* U: U represents the velocity or speed of the system at a particular point in the attractor 
* t: The time variable (discrete time steps which is incremented by approximately 0.0002500012500062 units of time) associated with each point in the Lorenz attractor. It indicates how much time has elapsed since the beginning of the simulation. Each value represents a specific point in time, and they are spaced apart by a fixed time interval.

# 3. Importing Code Modules

Here is the guide to install the HVT package. This helps user to install the most recent version of the HVT package.
```{r}
###direct installation###
#install.packages("HVT")

#or

###git repo installation###
#library(devtools)
#devtools::install_github(repo = "Mu-Sigma/HVT")

```


**NOTE:** At the time documenting this vignette, the updated changes were not still in CRAN, hence we are sourcing the scripts from the R folder directly to the session environment.

```{r, loading all the script files of the package, message=FALSE, warning=FALSE, include = TRUE}
# Sourcing required code scripts for HVT
script_dir <- "../R"
r_files <- list.files(script_dir, pattern = "\\.R$", full.names = TRUE)
invisible(lapply(r_files, function(file) { source(file, echo = FALSE); }))
```


# 4. Data Understanding

Here, we load the data. Let's explore the Lorenz Attractor Dataset. For the sake of brevity we are displaying only the first ten rows.


```{r,warning=FALSE,message=FALSE}
dataset <- read.csv("./sample_dataset/lorenze_attractor.csv")
dataset <- dataset %>% dplyr::select(X,Y,Z,U,t)
dataset$t <- round(dataset$t, 5)
Table(dataset, limit = 10)
```

Now let's try to visualize the Lorenz attractor (overlapping spirals) in  3D Space.

```{r, eval=TRUE,fig.cap='Figure 1: Lorenz attractor in 3D space'}
data_3d <- dataset[sample(1:nrow(dataset), 1000), ]
plot_3d <- plotly::plot_ly(data_3d, x= ~X, y= ~Y, z = ~Z) %>% add_markers( marker = list(
                          size = 2,
                          symbol = "circle",
                          color = ~Z,
                          colorscale = "Bluered",
                          colorbar = (list(title = 'Z'))))
plot_3d
```

Now let's have a look at **structure** of the Lorenz Attractor dataset.

```{r, message=FALSE, warning=FALSE}
str(dataset)
```

**Data distribution**

This section displays four objects.

1) *Variable Histograms*: The histogram distribution of all the variables in the dataset.

2) *Box Plots*: Box plots for each numeric column in the dataset across panels. These plots will display the median and Inter quartile Range of each column at a panel level.

3) *Correlation Matrix*: This calculates the pearson correlation which is a
bivariate correlation value measuring the linear correlation between two
numeric columns. The output plot is shown as a matrix.

4) *Summary EDA*: The table provides descriptive statistics for all the variables in the dataset.

It uses an inbuilt function called `edaPlots` to display the above mentioned four objects.

```{r, warning=FALSE,message=FALSE}
edaPlots(dataset, time_series = TRUE, time_column = 't')
```

**Train - Test Split**

Let us split the dataset into train and test. We will orderly select 80% of the data as train and remaining as test.

```{r}
noOfPoints <- dim(dataset)[1]
trainLength <- as.integer(noOfPoints * 0.8)
trainDataset <- dataset[1:trainLength,]
testDataset <- dataset[(trainLength+1):noOfPoints,]
rownames(testDataset) <- NULL
```


## 4.1 Training dataset

Let's have a look at the Training dataset containing 160,000 data points. For the sake of brevity we are displaying first 10 rows.

```{r,warning=FALSE,message=FALSE}
Table(trainDataset, limit = 10)
```

Now lets have a look at **structure** of the training dataset.

```{r train structure, warning=FALSE, eval = global_var}
str(trainDataset)
```

**Data Distribution**

```{r, train distribution, warning=FALSE,message=FALSE}
edaPlots(trainDataset, time_series = T, time_column = 't')
```

## 4.2 Testing dataset

Let's have a look at the Testing dataset containing 40,000 data points. For the sake of brevity we are displaying first 10 rows.

```{r, warning=FALSE,message=FALSE}
Table(testDataset, limit = 10)
```

Now lets have a look at **structure** of the testing dataset.

```{r test structure, warning=FALSE, eval = global_var}
str(testDataset)
```


**Data Distribution**

```{r, test distribution, warning=FALSE,message=FALSE}
edaPlots(testDataset, time_series = TRUE, time_column = 't')
```

# 5. Model Training and Visualization

We will use the `trainHVT` function to compress our dataset while preserving essential features.

**Model Parameters**

* Number of Cells at each Level = 100
* Maximum Depth = 1
* Quantization Error Threshold = 0.1
* Error Metric = Max
* Distance Metric = Manhattan / L1_Norm

**NOTE:** *The compression takes place only for the X, Y, Z coordinates and not for U(velocity) and t(Timestamp). After training & Scoring, we merge back the U and t column with the dataset.*

```{r ,warning=FALSE,fig.show='hold',results='hide',message=FALSE,eval = global_var}
set.seed(240)
hvt.results <- trainHVT(
  trainDataset[,-c(4:5)],
  n_cells = 100,
  depth = 1,
  quant.err = 0.1,
  normalize = TRUE,
  distance_metric = "L1_Norm",
  error_metric = "max",
  quant_method = "kmeans"
)

```


Let's checkout the compression summary . 

```{r compression summary torus first,warning=FALSE,eval = global_var}
displayTable(data = hvt.results[[3]]$compression_summary,columnName = 'percentOfCellsBelowQuantizationErrorThreshold', value = 0.8, tableType = "compression")
```
**NOTE:** *Based on the provided table, it's evident that the 'percentOfCellsBelowQuantizationErrorThreshold' value is zero, indicating that compression hasn't taken place for the specified number of cells, which is 100. Typically, we would continue increasing this value until at least 80% compression occurs. However, in this vignette demonstration, we're not doing so because the plots generated from dynamic analysis functions would become cluttered and complex, making explanations less clear.*

Now, Let's plot the Voronoi tessellation for 100 cells.

```{r, warning=FALSE,message=FALSE,fig.cap='Figure 2: The Voronoi tessellation for layer 1 shown for the 100 cells in the dataset ’lorenz attractor’', echo=FALSE, fig.align = "center", fig.show ='hold', message=FALSE, out.width='90%', results='asis', warning=FALSE}
plotHVT(
  hvt.results,
  centroid.size = c(0.6),
  plot.type = '2Dhvt'
)

```


# 6. Scoring

Now once we have built the model, let us try to score using our testing dataset. 

```{r scoreHVT function,warning=FALSE,message=FALSE,eval = global_var}
set.seed(240)
dataset_score <- testDataset[,-c(4:5)]
scoring_var <- scoreHVT(
  dataset_score,
  hvt.results,
  child.level = 1)
```

**The Flow Map functions mentioned in the next section requires Cell ID from scoring output and sorted Timestamp  from the dataset we used for scoring. So we merge them both to get a modified data frame that pairs cell IDs with their respective timestamps.**

Let’s see which cell and level each point belongs to with the sorted Timestamp. For the sake of brevity, we will only show the first 100 rows.


```{r scoreHVT,warning=FALSE,eval = global_var}
scored_data <- scoring_var[["scoredPredictedData"]] %>%round(2) %>% cbind(testDataset) %>% 
               as.data.frame()

colnames(scored_data) <- c("Segment.Level", "Segment.Parent", "Segment.Child", "n","Cell.ID",
                           "Quant.Error", "pred_X", "pred_Y", "pred_Z", "centroidRadius",
                           "diff", "anomalyFlag", "X", "Y", "Z", "U", "t")

displayTable(data =scored_data, columnName= 'Quant.Error', value = 0.1, tableType = "summary", limit =100)

```


# 7. Timeseries plot with State Transitions

Let's comprehend the function `plotStateTransition` which is used to create a time series plotly object.

```{r plotStateTransition function, echo=TRUE, eval=FALSE}
plotStateTransition(
       df,
       sample_size,
       line_plot,
       cellid_column,
       time_column 
)
```


* __`df`__  - A dataframe contains Cell ID and Timestamps.

* __`sample_size`__ - A numeric value to specify the sampling value which ranges between 0.1 to 1. The highest value 1, outputs a plot with the entire dataset. Sampling of data takes place from the last to first.

* __`line_plot`__ - A Logical value. If TRUE, the output will be a timeseries plot with a line connecting the states according to the sample_size. If FALSE, a timeseries plot but without a line based on the sample_size will be the output.

* __`cellid_column`__ - A Character specifying the column name of Cell ID from the dataframe passed to this function.

* __`time_column`__ - A Character specifying the column name of timestamp from the dataframe passed to this function.


```{r state_plot1, results='asis', warning=FALSE,message=FALSE}
plotStateTransition(df = scored_data, cellid_column = "Cell.ID", time_column = "t", sample_size = 1)
```

</br>


# 8. Transition probability tables


```{r getTransitionProbability,eval=FALSE}
getTransitionProbability(
        df, 
        cellid_column, 
        time_column)

```


* __`df`__  - A dataframe contains Cell ID and Timestamps.

* __`cellid_column`__  - A Character specifing the column name of Cell ID from the dataframe passed to this function.

* __`time_column`__ - A Character specifing the column name of timestamp from the dataframe passed to this function.

This function displays probability for Tplus1 states for all cells in the form of table. For the sake of brevity we are displaying the probability table for the Cell ID 1 to 5.

```{r, message=FALSE}
trans_table <- getTransitionProbability(df = scored_data, cellid_column = "Cell.ID", time_column = "t")
```

```{r}
Table(trans_table[[1]])
```

```{r}
Table(trans_table[[2]])
```

```{r}
Table(trans_table[[3]])
```

```{r}
Table(trans_table[[4]])
```

```{r}
Table(trans_table[[5]])
```



