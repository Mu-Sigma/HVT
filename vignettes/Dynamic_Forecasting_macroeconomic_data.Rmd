---
title: "Dynamic Forecasting of Macroeconomic Time Series Dataset using HVT"
author: "Zubin Dowlaty, Chepuri Gopi Krishna, Siddharth Shorya, Vishwavani"
date: "Created Date: 2024-11-12  <br> Modified Date: `r Sys.Date()`"
output:
  rmarkdown::html_vignette:
    toc: true
    toc_depth : 2
    tabset: true 
vignette: >
  %\VignetteIndexEntry{Dynamic Forecasting of Macroeconomic Time Series Dataset using HVT}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---



```{css, echo=FALSE}
/* CSS for floating TOC on the left side */
#TOC {
    /* float: left; */
    position: fixed;
    margin-left: -17vw;
    width: 15vw;
    height: fit-content;
    overflow-y: auto;
    padding-top: 20px;
    padding-bottom: 20px;
    background-color: #f9f9f9;
    border-right: 1px solid #ddd;
    margin-top: -13em; 
}
.main-container {
  margin-left: 250px; 
  padding: 20px;
  max-width: 1000px;/* Adjust this value to match the width of the TOC + some margin */
}
body{
max-width:1830px;
width: 60%;
min-width: 700px;
}
p {
text-align: justify;
}

.plotly {
  margin: auto;
  width: 100%;
  height: 200px;
}

.caption {
  text-align: center;
}
li {
  padding-bottom: 5px;
}
ul {
  margin-bottom: 0px !important;
}
img {
  border: none;
}
.custom-heatmap-plot g.legendlines {
    display: none;
  }

.tab{
   border: none !important;
}

#cells-3{
  background-color: green;
  font-size: 15px;
}

#cells-10{
  background-color: green;
  font-size: 15px;
}

```







# 1. Background

The HVT package offers a suite of R functions designed to construct <a href="https://link.springer.com/chapter/10.1007/1-84628-118-0_7" target="_blank">topology preserving maps</a> for in-depth analysis of multivariate data. It is particularly well-suited for datasets with numerous records. The package organizes the typical workflow into several key stages:

1.  **Data Compression**: Long datasets are compressed using Hierarchical Vector Quantization (HVQ) to achieve the desired level of data reduction.

2.  **Data Projection**:  Compressed cells are projected into one and two dimensions using dimensionality reduction algorithms, producing <a href="https://en.wikipedia.org/wiki/Embedding" target="_blank">embeddings</a> that preserve the original topology. This allows for intuitive visualization of complex data structures.

3.  **Tessellation**: Voronoi tessellation partitions the projected space into distinct cells, supporting hierarchical visualizations. Heatmaps and interactive plots facilitate exploration and insights into the underlying data patterns.

4.  **Scoring**: Test dataset is evaluated against previously generated maps, enabling their placement within the existing structure. Sequential application across multiple maps is supported if required.

5. **Temporal Analysis and Visualization**: Functions in this stage examine time-series data to identify patterns, estimate transition probabilities, and visualize data flow over time.


<span style="font-size: 20px;">**What's New?**</span>

**HVT – Version 25.2.4**

This notebook introduces a new feature, **MSM** (Monte Carlo Simulation of Markov Chains), in the HVT package. MSM is designed for **dynamic forecasting of time series data** using a transition probability matrix to forecast *n* states ahead.

The workflow supports both:

* **Ex-post forecasting** (validation on historical data)
* **Ex-ante forecasting** (forward-looking predictions)

The notebook provides a step-by-step walkthrough covering data preparation, model setup, and forecast generation. It also highlights challenges arising from transition probability issues in certain states, outlines mechanisms to handle such problematic states, and evaluates forecast performance using appropriate accuracy metrics.

**HVT – Version 25.2.8**

In this latest version of notebook, introducing an enhancement to dynamic forecasting with the release of **raw series ex-ante forecasting**. In this approach, a **simple 12-month direct lookback method** is used, where raw historical values combined with the forecasted **year-over-year (YoY)** changes are applied to generate raw-level forecasts for each feature over the ex-ante period.

</br>

# 2. Notebook Requirements

This chunk verifies the installation of all the necessary packages to successfully run this vignette, if not, the code will install those packages and attach to the session environment.

```{r, warning=FALSE, message=FALSE}
list.of.packages <- c("dplyr", "tidyr","patchwork", "feather","ggplot2","kableExtra", "htmltools",
                      "plotly","tibble","purrr", "gganimate", "DT","readr", "NbClust")

new.packages <-list.of.packages[!(list.of.packages %in% installed.packages()[, "Package"])]
if (length(new.packages))
  install.packages(new.packages, dependencies = TRUE, verbose = FALSE, repos='https://cloud.r-project.org/')
invisible(lapply(list.of.packages, library, character.only = TRUE))
```

Sourcing all the R scripts, as the new function for ex-ante raw series forecasting is yet to be released in CRAN.
 
```{r, loading all the script files of the package, message=FALSE, warning=FALSE, include = TRUE}
# Sourcing required code scripts for HVT
script_dir <- "../R"
r_files <- list.files(script_dir, pattern = "\\.R$", full.names = TRUE)
invisible(lapply(r_files, function(file) { source(file, echo = FALSE); }))
```

Below is the function for more dynamic drop down display in the data tables.

```{r}
calculate_dynamic_length_menu <- function(total_entries, base_step = 100) {
  max_option <- ceiling(total_entries / base_step) * base_step
  max_option <- max(max_option, 100)
  options <- seq(base_step, by = base_step, length.out = max_option / base_step)
  options <- c(10, options)
  return(options)}
```


# 3. Dataset Preparation and Exploration


## 3.1 Dataset Loading

Let's start with importing the dataset. The below code reads and displays the dataset.

```{r,warning=FALSE,message=FALSE}
entire_dataset_raw <- read.csv("./sample_dataset/macro_eco_data_2025.csv")
entire_dataset_raw <-  entire_dataset_raw %>% mutate(across(where(is.numeric), ~ round(., 4)))
dynamic_length_menu <- calculate_dynamic_length_menu(nrow(entire_dataset_raw))
datatable(entire_dataset_raw,options = list(pageLength = 10,scrollX = TRUE, lengthMenu = dynamic_length_menu), rownames = FALSE)
```

This dataset includes a collection of key economic and financial indicators. These indicators are essential for monitoring macroeconomic performance, analyzing market trends, and assessing financial stability. The data ranges from **December 1998 to September 2025.**


## 3.2 Dataset Preprocessing

Before proceeding, it is crucial to examine the structure of the dataset. This involves verifying the data types of the columns and resolving any inconsistencies. Make sure all data types are accurate and suitable for the intended functions.

```{r}
str(entire_dataset_raw)
```


Since the time column is in 'Character' format, we are changing it to 'datetime' (POSIXct) format.

```{r}
entire_dataset_raw$t <- as.POSIXct(paste0(entire_dataset_raw$t, "/01"), format = "%Y/%m/%d")
```


## 3.3 Dataset Transformation

We transform the data to compute the 12-month rate of change, which standardizes the features and brings them to a comparable scale, simplifying the analysis of their relative changes. Log difference reduces variability and removes trends, stabilizing the data for more accurate forecasting.

The Rate of change is calculated as follows:

$$
\text{Rate of Change} = \log(\text{Current Value}) - \log(\text{12-Month Lag Value})
$$


```{r}
entire_dataset <- entire_dataset_raw
features_data <- entire_dataset %>% select(-t) %>% colnames()
entire_dataset[features_data] <- lapply(entire_dataset[features_data], function(x) as.numeric(as.character(x)))

invisible(lapply(features_data, function(col) {
  entire_dataset[[col]] <<- entire_dataset[[col]] %>% log()
  entire_dataset[[col]] <<- c(rep(NA, 12), round(diff(entire_dataset[[col]], 12),4))}))
entire_dataset <- entire_dataset %>% na.omit() %>% data.frame()
rownames(entire_dataset) <- NULL
```

After the log difference of 12 datapoints (months), the dataset ranges from **December 1999 to September 2025**. Below is the table displaying the transformed dataset.

```{r}
entire_dataset$t <- as.character(entire_dataset$t)
dynamic_length_menu <- calculate_dynamic_length_menu(nrow(entire_dataset))
datatable(entire_dataset,options = list(pageLength = 10,scrollX = TRUE,lengthMenu = dynamic_length_menu,columnDefs = list(list(width = '150px', targets = 0))),
class = "nowrap display",rownames = FALSE)
entire_dataset$t <- as.POSIXct(entire_dataset$t, format = "%Y-%m-%d")
```


## 3.4 Data split

The ultimate goal of this notebook is to dynamically forecast the HVT states in both ex-post and ex-ante scenarios. To structure the analysis, we will define the timelines based on the main topics of interest:

- **Constructing HVT Model:** 1999-12-01 to 2024-09-01  

- **Scoring Using HVT Model:** 1999-12-01 to 2025-09-01  (as actual states needed for ex-post actuals and  studentized residuals)

- **Dynamic Forecasting**
  - *Transition Probability Matrix:* 1999-12-01 to 2024-09-01  
  - *Ex-post Forecasting:* 2024-10-01 to 2025-09-01  
  - *Ex-ante Forecasting:* 2025-10-01 to 2026-09-01  

```{r}
trainHVT_data <- entire_dataset[-tail(seq_len(nrow(entire_dataset)), 12), ]
expost_forecasting <- entire_dataset[entire_dataset$t > "2024-09-01" & entire_dataset$t <= "2025-09-01", ]
```


## 3.5 EDA Plots {.tabset}

For the Exploratory Data Analysis (EDA), we will create a statistic table and series of plots to visualize the dataset's distribution, trends, and relationships. These plots provide insights into the data structure, enabling a better understanding of the underlying patterns and correlations.

**Dataset used for EDA: 1999-12-01 to 2025-09-01**

For creating tabsets, follow this markdown syntax;

```{r, eval=FALSE}
## Main Heading {.tabset}
### Tab 1
 - Content for Tab 1.
### Tab 2
 - Content for Tab 2.
## Next Section
```



### Summary Table

```{r}
edaPlots(entire_dataset)
```

### Histograms



```{r plot twohist,figures-side,  warning = FALSE, message=FALSE}
edaPlots(entire_dataset, output_type = 'histogram')
```

</br>

### Boxplots  


```{r plot twobox,figures-side, warning = FALSE, message=FALSE}
edaPlots(entire_dataset, output_type = 'boxplot')
```


</br>

### Correlation Plot

```{r plot twocor, fig.show="hold", fig.width = 8, fig.height = 8, fig.align='center', warning = FALSE, message=FALSE}
edaPlots(entire_dataset, output_type = 'correlation')
```

</br>

### Time Series Plots 

```{r, plot twotime, warning = FALSE, message=FALSE, fig.align='center',fig.width=9.2, fig.height= 15}
recession_periods <- list(c("2001-03-01", "2001-11-01"),c("2007-12-01", "2009-06-01"),c("2020-02-01", "2020-04-01"))
recession_periods <- lapply(recession_periods, function(x) as.POSIXct(x))
edaPlots(entire_dataset, time_column = "t", output_type = "timeseries", grey_bars = recession_periods)
```


</br>



</br>


# 4. Constructing and Visualizing the HVT Model

The dataset is prepped and ready for constructing the HVT model, which is the first and most prominent step. Model Training involves applying Hierarchical Vector Quantization (HVQ) to iteratively compress and project data into a hierarchy of cells. The process uses a quantization error threshold to determine the number of cells and levels in the hierarchy. The compressed data is then projected onto a 2D space, and the resulting tessellation provides a visual representation of the data distribution, enabling insights into the underlying patterns and relationships.

We use the `trainHVT` function to compress the dataset, and timestamp feature is not needed for this process.

**Input Parameters**

* Dataset (1999-12-01 to 2024-09-01)
* Number of Cells = 75
* Depth = 1
* Quantization Error Threshold = 0.25
* Error Metric = Max
* Distance Metric = L1_Norm/Manhattan
* Dimension Reduction Metric = Sammon
* Normalization = TRUE (Z-score)

```{r ,warning=FALSE,fig.show='hold',message=FALSE, results='hide'}
hvt.results <- trainHVT(
  trainHVT_data[,-1],
  n_cells = 75,
  depth = 1,
  quant.err = 0.25,
  normalize = TRUE,
  distance_metric = "L1_Norm",
  error_metric = "max",
  quant_method = "kmeans",
  dim_reduction_method = "sammon")
```


```{r compression summary torus first,warning=FALSE}
summary(hvt.results)
```

The value of `percentOfCellsBelowQuantizationErrorThreshold` is crucial for evaluating the model's performance and the quality of the compression. It is recommended to construct a model where atleast 80% of the cells fall below the quantization error threshold.

The value `r round(hvt.results[[3]]$compression_summary$percentOfCellsBelowQuantizationErrorThreshold,2)`, indicates that **`r round((hvt.results[[3]]$compression_summary$percentOfCellsBelowQuantizationErrorThreshold),2) * 100`% compression** has been achieved, Typically, the number of cells is increased till, atleast 80% compression is achieved. However, for this vignette, we proceed with the current level of compression, as this specific combination of cells and dataset intentionally induces problematic transition states, which are useful for demonstrating the proposed solution.



### Visual Stability & Aesthetics {.tabset}

For the visual stability and aesthetic check, we will plot and compare our current model with tessellations from 3 cells above and below our current cell count of 75. This comparison helps ensure the model's structural integrity across a similar range of cells and allows for the identification of any significant sudden structural changes.



#### 78 Cells

```{r, warning=FALSE, message=FALSE, results = "hide", include=FALSE, eval=TRUE}
hvt.results_2 <- trainHVT(
  trainHVT_data[,-1],
  n_cells = 78,
  depth = 1,
  quant.err = 0.25,
  normalize = TRUE,
  distance_metric = "L1_Norm",
  error_metric = "max",
  quant_method = "kmeans",
  dim_reduction_method = "sammon")
```


```{r,warning = FALSE, message = FALSE, fig.align = "center",fig.width = 8, fig.height = 6.5}
plotHVT(hvt.results_2,plot.type = '2Dhvt', cell_id = TRUE)
```

#### 77 Cells

```{r, warning=FALSE, message=FALSE, results = "hide", include=FALSE, eval=TRUE}
hvt.results_3 <- trainHVT(
  trainHVT_data[,-1],
  n_cells = 77,
  depth = 1,
  quant.err = 0.25,
  normalize = TRUE,
  distance_metric = "L1_Norm",
  error_metric = "max",
  quant_method = "kmeans",
  dim_reduction_method = "sammon")
```


```{r,warning = FALSE, message = FALSE, fig.align = "center",fig.width = 8, fig.height = 6.5}
plotHVT(hvt.results_3,plot.type = '2Dhvt', cell_id = TRUE)
```

#### 76 Cells

```{r, warning=FALSE, message=FALSE, results = "hide", include=FALSE, eval=TRUE}
hvt.results_4 <- trainHVT(
  trainHVT_data[,-1],
  n_cells = 76,
  depth = 1,
  quant.err = 0.25,
  normalize = TRUE,
  distance_metric = "L1_Norm",
  error_metric = "max",
  quant_method = "kmeans",
  dim_reduction_method = "sammon")
```


```{r,warning = FALSE, message = FALSE, fig.align = "center",fig.width = 8, fig.height = 6.5}
plotHVT(hvt.results_4,plot.type = '2Dhvt', cell_id = TRUE)
```

#### 75 Cells


```{r,warning = FALSE, message = FALSE, fig.align = "center",fig.width = 8, fig.height = 6.5}
plotHVT(hvt.results,plot.type = '2Dhvt', cell_id = TRUE)
```

#### 74 Cells

```{r, warning=FALSE, message=FALSE, results = "hide", include=FALSE, eval=TRUE}
hvt.results_5 <- trainHVT(
  trainHVT_data[,-1],
  n_cells = 74,
  depth = 1,
  quant.err = 0.25,
  normalize = TRUE,
  distance_metric = "L1_Norm",
  error_metric = "max",
  quant_method = "kmeans",
  dim_reduction_method = "sammon")
```


```{r,warning = FALSE, message = FALSE, fig.align = "center",fig.width = 8, fig.height = 6.5}
plotHVT(hvt.results_5,plot.type = '2Dhvt', cell_id = TRUE)
```

#### 73 Cells

```{r, warning=FALSE, message=FALSE, results = "hide", include=FALSE, eval=TRUE}
hvt.results_6 <- trainHVT(
  trainHVT_data[,-1],
  n_cells = 73,
  depth = 1,
  quant.err = 0.25,
  normalize = TRUE,
  distance_metric = "L1_Norm",
  error_metric = "max",
  quant_method = "kmeans",
  dim_reduction_method = "sammon")
```


```{r,warning = FALSE, message = FALSE, fig.align = "center",fig.width = 8, fig.height = 6.5}
plotHVT(hvt.results_6,plot.type = '2Dhvt', cell_id = TRUE)
```

#### 72 Cells

```{r, warning=FALSE, message=FALSE, results = "hide", include=FALSE, eval=TRUE}
hvt.results_7 <- trainHVT(
  trainHVT_data[,-1],
  n_cells = 72,
  depth = 1,
  quant.err = 0.25,
  normalize = TRUE,
  distance_metric = "L1_Norm",
  error_metric = "max",
  quant_method = "kmeans",
  dim_reduction_method = "sammon")
```


```{r,warning = FALSE, message = FALSE, fig.align = "center",fig.width = 8, fig.height = 6.5}
plotHVT(hvt.results_7,plot.type = '2Dhvt', cell_id = TRUE)
```

### Conclusion

Within three cells above and below the trained model (i.e., 75), there are no flips or major structural changes. This indicates that the cell range is visually stable, making 75 cells an appropriate choice to proceed with.

### Heatmaps {.tabset}

Below are the heatmaps for the trained HVT model, including those for 'n' (the number of records in a cell) and each feature.

#### n

```{r, warning=FALSE,message=FALSE, fig.align = "center", fig.show ='hold', include=TRUE, results='asis', fig.width = 8, fig.height = 6.5}
plotHVT(hvt.results,hmap.cols = "n",plot.type = '2Dheatmap', cell_id = TRUE)
```

#### CPI_Food

```{r, warning=FALSE,message=FALSE, fig.align = "center", fig.show ='hold', include=TRUE, results='asis', fig.width = 8, fig.height = 6.5}
plotHVT(hvt.results,hmap.cols = "CPI_Food",plot.type = '2Dheatmap', cell_id = TRUE)
```

#### COIN

```{r, warning=FALSE,message=FALSE, fig.align = "center", fig.show ='hold', include=TRUE, results='asis', fig.width = 8, fig.height = 6.5}
plotHVT(hvt.results,hmap.cols = "COIN",plot.type = '2Dheatmap', cell_id = TRUE)
```

#### Copper_ETF

```{r, warning=FALSE,message=FALSE,fig.align = "center", fig.show ='hold', include=TRUE, results='asis', fig.width = 8.5, fig.height = 6.5 }
plotHVT(hvt.results,hmap.cols = "Copper_ETF",plot.type = '2Dheatmap', cell_id = TRUE)
```


#### SnP500_ETF

```{r, warning=FALSE,message=FALSE,fig.align = "center", fig.show ='hold', include=TRUE, results='asis', fig.width = 8.5, fig.height = 6.5 }
plotHVT(hvt.results,hmap.cols = "SnP500_ETF",plot.type = '2Dheatmap', cell_id = TRUE)
```



#### Spot_Oil
 
```{r, warning=FALSE,message=FALSE, fig.align = "center", fig.show ='hold', include=TRUE, results='asis', fig.width = 8.5, fig.height = 6.5 }
plotHVT(hvt.results,hmap.cols = "Spot_Oil",plot.type = '2Dheatmap', cell_id = TRUE)
```

#### USD_Index
 
```{r, warning=FALSE,message=FALSE,fig.align = "center", fig.show ='hold', include=TRUE, results='asis', fig.width = 8.5, fig.height = 6.5 }
plotHVT(hvt.results,hmap.cols = "USD_Index",plot.type = '2Dheatmap', cell_id = TRUE)
```

#### Unemp_Rate
 
```{r, warning=FALSE,message=FALSE,fig.align = "center", fig.show ='hold', include=TRUE, results='asis', fig.width = 8.5, fig.height = 6.5 }
plotHVT(hvt.results,hmap.cols = "Unemp_Rate",plot.type = '2Dheatmap', cell_id = TRUE)
```

#### Y10_Note
 
```{r, warning=FALSE,message=FALSE, fig.align = "center", fig.show ='hold', include=TRUE, results='asis', fig.width = 8.5, fig.height = 6.5 }
plotHVT(hvt.results,hmap.cols = "Y10_Note",plot.type = '2Dheatmap', cell_id = TRUE)
```

#### Y2_Note
 
```{r, warning=FALSE,message=FALSE, fig.align = "center", fig.show ='hold', include=TRUE, results='asis', fig.width = 8.5, fig.height = 6.5 }
plotHVT(hvt.results,hmap.cols = "Y2_Note",plot.type = '2Dheatmap', cell_id = TRUE)
```

#### Yield_Curve
 
```{r, warning=FALSE,message=FALSE,fig.align = "center", fig.show ='hold', include=TRUE, results='asis', fig.width = 8.5, fig.height = 6.5 }
plotHVT(hvt.results,hmap.cols = "Yield_Curve",plot.type = '2Dheatmap', cell_id = TRUE)
```

#### XLY
 
```{r, warning=FALSE,message=FALSE,fig.align = "center", fig.show ='hold', include=TRUE, results='asis', fig.width = 8.5, fig.height = 6.5 }
plotHVT(hvt.results,hmap.cols = "XLY",plot.type = '2Dheatmap', cell_id = TRUE)
```

#### XLP
 
```{r, warning=FALSE,message=FALSE,fig.align = "center", fig.show ='hold', include=TRUE, results='asis', fig.width = 8.5, fig.height = 6.5 }
plotHVT(hvt.results,hmap.cols = "XLP",plot.type = '2Dheatmap', cell_id = TRUE)
```

#### XLE
 
```{r, warning=FALSE,message=FALSE,fig.align = "center", fig.show ='hold', include=TRUE, results='asis', fig.width = 8.5, fig.height = 6.5 }
plotHVT(hvt.results,hmap.cols = "XLE",plot.type = '2Dheatmap', cell_id = TRUE)
```

#### XLF
 
```{r, warning=FALSE,message=FALSE,fig.align = "center", fig.show ='hold', include=TRUE, results='asis', fig.width = 8.5, fig.height = 6.5 }
plotHVT(hvt.results,hmap.cols = "XLF",plot.type = '2Dheatmap', cell_id = TRUE)
```

#### XLV
 
```{r, warning=FALSE,message=FALSE,fig.align = "center", fig.show ='hold', include=TRUE, results='asis', fig.width = 8.5, fig.height = 6.5 }
plotHVT(hvt.results,hmap.cols = "XLV",plot.type = '2Dheatmap', cell_id = TRUE)
```

#### XLI
 
```{r, warning=FALSE,message=FALSE,fig.align = "center", fig.show ='hold', include=TRUE, results='asis', fig.width = 8.5, fig.height = 6.5 }
plotHVT(hvt.results,hmap.cols = "XLI",plot.type = '2Dheatmap', cell_id = TRUE)
```

#### XLB
 
```{r, warning=FALSE,message=FALSE,fig.align = "center", fig.show ='hold', include=TRUE, results='asis', fig.width = 8.5, fig.height = 6.5 }
plotHVT(hvt.results,hmap.cols = "XLB",plot.type = '2Dheatmap', cell_id = TRUE)
```

### Centroid Table 

The centroid of a cell is the average value of all the records within that cell in the multidimensional space. Below is the table displaying the centroids of all 75 cells of the trained HVT Model in 2D. In this table, *n* represents the number of records contained within each cell.

```{r, warning=FALSE,message=FALSE}
col_names <- c("Cell.ID","n" ,features_data)
data <- hvt.results[[3]][["summary"]] %>% select(col_names) %>% arrange(Cell.ID) %>% round(2)
dynamic_length_menu <- calculate_dynamic_length_menu(nrow(data))
datatable(data, options = list(pageLength = 10, scrollX = TRUE,lengthMenu = dynamic_length_menu), 
rownames = FALSE )
```


### Z-Score Plots

A Z-score plot visualizes how many standard deviations a data point is from the mean. The plot helps to identify outliers and assess the distribution of data. Here, we are plotting the Z-scores with a confidence interval of +1.65 and -1.65.

Let's look at the signature and parameters of the `plotZscore` function.

```{r plotStateTransition function, echo=TRUE, eval=FALSE}
plotZscore(data,
           cell_range,
           segment_size,
           reference_lines)
```


* __`data`__  - A data frame of cell id and features. 

* __`cell_range`__ - A numeric vector of cell id range for which the plot should be displayed. Default is NULL, which plots all the cells.

* __`segment_size`__ - A numeric value to indicate the size of the bars in the plot. Default is 2.

* __`reference_lines`__ - A numeric vector of confidence interval values for the reference lines in the plot. Default is c(-1.65, 1.65).


Below are the Z-score plots of all features in the dataset for cells 1 to 75.

```{r, warning=FALSE,message=FALSE, fig.height=55, fig.width=12, out.width="100%"}
data <- data %>% select(-n)
invisible(plotZscore(data))
```




# 5. Scoring the trained HVT Model

Once the model is constructed, the next key step is scoring the data points using the trained HVT model. Scoring involves assigning each data point to a specific cell based on the trained model. This process helps map data points to their correct hierarchical cell without the need for forecasting.

The scoring is performed on the **Dataset (1999-12-01 to 2025-09-01)**. This is crucial for time series analysis and forecasting, as it provides the data of cells over time.

```{r scoreHVT function,warning=FALSE,message=FALSE}
scoring <- scoreHVT(entire_dataset,hvt.results,analysis.plots = TRUE,names.column = entire_dataset[,1])
scoring$scoredPredictedData$t <- format(entire_dataset$t, "%Y-%m-%d")
scoring$scoredPredictedData <- scoring$scoredPredictedData %>% dplyr::select(c(t, everything()))
```

Below is the table displaying scored data.

```{r}
dynamic_length_menu <- calculate_dynamic_length_menu(nrow(scoring$scoredPredictedData))
datatable(scoring$scoredPredictedData,options = list(pageLength = 10,scrollX = TRUE,lengthMenu = dynamic_length_menu,
columnDefs = list(list(width = '150px', targets = 0))),class = "nowrap display",rownames = FALSE)
```

These are the brief explanation of all the features in the above table.

- **Segment Level**: The tier or depth of a segment in the hierarchical structure.

- **Segment Parent**: The ID of the larger segment that this segment is part of in the level above.

- **Segment Child**: The IDs of smaller segments that are contained within this segment in the level below.

- **n**: The number of entities/data points from the uploaded dataset that are present inside that Segment child.

- **Cell.ID**: The ID of the child which is the result of sorted 1D Sammon's.

- **Quant.Error**: The quantization error of that cell.

- **centroidRadius**: The maximum quantization error values as radius for anomalies.

- **diff**: The difference between centroidRadius and Quant.Error.

- **anomalyFlag**: The binary value that says the cell is an anomaly or not. (if the Quant.Error is greater than mad.threshold then it is = 1 (anomaly) else = 0 (not an anomaly))


Below is the plotly of scored data. On Hovering over the plot, the Cell.ID, Number of observations of a cell & the timestamps of those observations are displayed.

```{r, warning=FALSE, fig.width = 8, fig.height = 6.5}
scoring$scoredPlotly
```


# 6. Temporal Analysis and Visualization

Now that scoring is complete, we have a time series of state transitions, that captures the progression of states over time, enabling the analysis of transitions and patterns for the forecasting process. We will prepare this dataset by combining the `t` timestamp column with the scored dataset.

**Dataset used for Temporal Analysis: 1999-12-01 to 2024-09-01**

```{r}
temporal_data_entire <-scoring$scoredPredictedData %>% select(t,Cell.ID)
temporal_data <- temporal_data_entire[-tail(seq_len(nrow(temporal_data_entire)), 12), ]
dynamic_length_menu <- calculate_dynamic_length_menu(nrow(temporal_data))
datatable(temporal_data,rownames = FALSE,options=list(lengthMenu = dynamic_length_menu))
temporal_data$t <- as.POSIXct(temporal_data$t, format = "%Y-%m-%d")
temporal_data_entire$t <-as.POSIXct(temporal_data_entire$t, format = "%Y-%m-%d")
```



### State Transition Plots {.tabset}

In this section, we will visualize the transitions of states of the dataset over time from 
**1999-12-01 to 2024-09-01**.



#### Heatmap line plot

```{r, warning=FALSE,message=FALSE, fig.width = 11.5, fig.height = 6,out.width="1200px" }
plotStateTransition(df = temporal_data,cellid_column = "Cell.ID",time_column = "t",sample_size = 1, line_plot = TRUE,time_periods = recession_periods)
```

#### Heatmap scatter plot
```{r, warning=FALSE, fig.width = 11.5, fig.height = 6,out.width="1200px"}
plotStateTransition(df = temporal_data,cellid_column = "Cell.ID",time_column = "t",sample_size = 1, time_periods =recession_periods)    
```

### Transition Probability Table

Let's calculate the transition probability of temporal_data using the `getTransitionProbability` function **with self-states**.

**Dataset for Transition Probability Matrix:  1999-12-01 to 2024-09-01**

```{r, message=FALSE}
prob_trans_matx <- getTransitionProbability(df = temporal_data,cellid_column = "Cell.ID",time_column = "t", type = "with_self_state")
dynamic_length_menu <- calculate_dynamic_length_menu(nrow(prob_trans_matx))
datatable(prob_trans_matx,rownames = FALSE,options =list(lengthMenu = dynamic_length_menu))
```



</br>

Below are brief explanations of the features in the transition probability matrix.

- *Current_State*: The cell in which the datapoint resides at a given time (t).

- *Next_State*: The cell to which the datapoint moves at the next time unit (t+1).

- *Relative_Frequency*: The number of times that the datapoint moves from that `Current_State` to that `Next_State`.

- *Transition_Probability*: The probability calculated from the `Relative_Frequency`. Individual `Relative_Frequency` divided by the total of `Relative_Frequency` for a particular `Current_State`.

- *Cumulative_Probability*: The sum of the `Transition_Probability` for all the `Next_State` for a particular `Current_State`.


### Flowmaps & Animations {.tabset}

Flowmaps visualize the flow of data between states over time including and excluding self states to identify patterns and trends. The animations provide a dynamic representation of the data flow, enabling a comprehensive understanding of state transitions and their evolution over time.

- The Self State Flowmap including self-state transitions, is represented by the circle size around each cell, where larger sizes indicate a stronger likelihood of staying in the same cell.

- The Non-Self State Flowmap, excluding self-state transitions, is represented by arrow sizes, where larger arrows indicate higher probabilities of transitioning to the next state, with arrow directions showing the target cell.

- The Time-based Animation, including self-state transitions, is represented by a red point moving through cells over time, with blinks indicating the duration of staying in the same cell, as shown in the plot's sub-header.

- The State-based Animation, excluding self-transitions, shows an arrow moving between cells, with its length indicating transition probabilities. The animation highlights movement between states over time.

**Dataset for generating flowmaps and animations:  1999-12-01 to 2024-09-01**

```{r, warning=FALSE,out.width = "672px", out.height = "480px", fig.width = 8.5, fig.height = 6.5,fig.align = "center"}
flowmap_plots <- plotAnimatedFlowmap(hvt_model_output = hvt.results,
                                transition_probability_df =prob_trans_matx,
                                 df = temporal_data,
                                 animation = "All" , flow_map = "All",
                                fps_time = 10,time_duration = 30,
                               fps_state = 10,state_duration = 30,
                              cellid_column = "Cell.ID", time_column = "t")
```

#### Self State Flowmap

```{r, warning=FALSE, fig.width=9,fig.height=5.5, fig.align='center'}
flowmap_plots$self_state
```


#### Non-Self State Flowmap


```{r, fig.width=9, fig.height=5.5,fig.align='center', warning=FALSE}
flowmap_plots$without_self_state
```

#### Time-based Animation


```{r,  warning=FALSE, fig.align='center'}
flowmap_plots$time_based
```

#### State-based Animation


```{r,  warning=FALSE, fig.align='center'}
flowmap_plots$state_based
```


# 7. Ex-post Dynamic Forecasting

Now that temporal analysis is complete, we have a clear understanding of the data pattern over time. In this section, we will focus on the next key process: **Dynamic Forecasting of the states for the ex-post period** using the new function `msm` — Monte Carlo Simulations of the Markov Chain.

**How MSM works?**

This function uses a transition probability matrix with cumulative probabilities summing to 1. Given the initial state, a random number is generated from a uniform distribution of 0 to 1, and the next state is chosen based on where the random number is less than or equal to the cumulative probability. This next state becomes the new current state, and the process continues to simulate states throughout the given t+n period. 

**MSM Function Parameters Explanation**

* __`state_time_data`__ - Dataframe with columns of cell.ID and the timestamp.

* __`forecast_type`__ - Character vector to indicate the type of forecasting. It can be `ex-post` or `ex-ante`.

* __`transition_probability_matrix`__  - Dataframe of transition probabilities of all states from the `getTransitionProbability` function.

* __`initial_state`__   - Integer, indicating the state at t0.

* __`n_ahead_ante`__   - Integer, indicating the number of ahead periods for ex-ante forecasting. Default value is 10.

* __`num_simulations`__ - Integer indicating the number of simulations to be performed. Default value is 100.

* __`trainHVT_results`__	- Nested list containing the results from the trainHVT function. This parameter is used to retrieve the HVQ-compressed centroid points for feature forecast plots.

* __`scoreHVT_results`__	- Nested list of the results from the `scoreHVT` function. This parameter is used to retrieve the centroid coordinates for feature forecast plots & clustering analysis.

* __`actual_data`__ - DataFrame of the raw dataset for the ex-post forecasting period, used for plotting the Actual line in forecasting plots and calculating residuals for MAE. It is applicable only for 'ex-post'.

* __`raw_dataset`__ - DataFrame of the entire raw dataset, used to calculate the mean and standard deviation of all features for scaling up the predicted values.

* __`handle_problematic_states`__ - Logical flag to handle the state transition problems and proceed with clustering analysis. Default value is TRUE.

* __`k`__ - Integer to specify the number of clusters for the clustering algorithm. Default value is 5.
    
* __`n_nearest_neighbor`__ -  Integer to specify the number of nearest neighbors to be selected for the clustering algorithm. Default value is 1. If a number larger than the total states within a cluster is provided, the number of nearest neighbors will default to the total number of states in that cluster. For instance, if a cluster has 5 states including the problematic state and if the n_nearest_neighbor is set to 7, the number of nearest neighbors will only be 4.

* __`time_column`__ - Character string specifying the column name of the time stamp.

* __`show_simulation`__ - Logical flag to display the simulation lines in plots. Default value is TRUE.

* __`mae_metric`__ - Character to indicate which central tendency measure should be selected for calculating residuals for studentized residual plot. Only 'mean', 'median' or 'mode' is allowed. Default value is 'median'.



**Function Outputs**

The function returns a list containing the following elements:

1) *Simulation Plots*: A collection of plots illustrating the forecasted states and centroids for both ex-post and ex-ante analyses.

- **Ex-post plots**: 
- These plots compare actual states and predicted states, as well as actual raw values and predicted centroid-scaled values for each feature including central tendencies (mean, median & mode). 

- The predicted states from the simulations are translated to respective feature centroids from the `trainHVT (HVQ compression)` and scaled to the raw dataset values by multiplying them by the standard deviation of the raw feature and adding the mean of the raw feature (if data is normalized during model training). 

- The x-axis represents the time period, and the y-axis represents the states (in states plot) and transformed values (means the data is log diffed and scaled in trainHVT) in feature plots. 

- The studentized residuals plot illustrates standardized prediction errors, calculated by dividing the raw residuals (actual - predicted mae_metric) by their standard deviation. The plot includes blue dashed lines at ±1σ and a black dashed line at 0, representing control limits. This helps identify significant deviations between predicted and actual values.

- **Ex-ante plots**:

- Similar to the ex-post plots, but without the actual data, showing only the predicted states. The x-axis represents the time period, and the y-axis represents the states (in states plot) and transformed values.

- Residual plots are not applicable since there are no actual values available.

2) Additionally, when `handle_problematic_states` is TRUE, the function returns a dendrogram plot, a cluster heatmap for the given `k` with the nearest neighbors highlighted, and a table of problematic states with their nearest neighbors.

Let's proceed with the ex-post Dynamic Forecasting using the `msm` function.

**Ex-post Period:**

- Transition Probability Matrix: 1999-12-01 to 2024-09-01

- Initial timestamp: 2024-09-01

- Initial state: 16

- Ex-post Forecast: 2024-10-01 to 2025-09-01

- Residuals: Actual - Predicted Median.

NOTE: We have selected `Median` as the metric for calculating residuals throughout this notebook.

```{r, warning=FALSE, message=FALSE,fig.align = "center", results='hide'}
ex_post <- msm(state_time_data = temporal_data_entire,
               forecast_type = "ex-post",
               transition_probability_matrix = prob_trans_matx,
               initial_state =  tail(temporal_data$Cell.ID, 1),
               num_simulations = 500,
               scoreHVT_results = scoring,
               trainHVT_results = hvt.results,
               actual_data = expost_forecasting,
               raw_dataset = entire_dataset,
               handle_problematic_states = FALSE,
               mae_metric = "median",
               show_simulation = FALSE,
               time_column = "t")
```


#### Ex-post plots without simulation lines {.tabset}


##### States

```{r, fig.width=8.5, out.width='100%',fig.height=6, fig.align='center'}
ex_post[["plots"]][[2]][[1]]
```




#####  CPI_Food

```{r, fig.width=8.5, out.width='100%',out.height='10%', fig.align='center'}
ex_post[["plots"]][[1]][[1]]$centroids_plot
```


#####  COIN

```{r, fig.width=8.5, out.width='100%',fig.height=6, fig.align='center'}
ex_post[["plots"]][[1]][[2]]$centroids_plot
```

#####  Copper_ETF

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_post[["plots"]][[1]][[3]]$centroids_plot
```

#####  SnP500_ETF

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_post[["plots"]][[1]][[4]]$centroids_plot
```

#####  Spot_Oil

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_post[["plots"]][[1]][[5]]$centroids_plot
```

#####  USD_Index

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_post[["plots"]][[1]][[6]]$centroids_plot
```


#####  Unemp_Rate

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_post[["plots"]][[1]][[7]]$centroids_plot
```

#####  Y10_Note

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_post[["plots"]][[1]][[8]]$centroids_plot
```

#####  Y2_Note

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_post[["plots"]][[1]][[9]]$centroids_plot
```

#####  Yield_Curve

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_post[["plots"]][[1]][[10]]$centroids_plot
```

#####  XLY

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_post[["plots"]][[1]][[11]]$centroids_plot
```

#####  XLP

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_post[["plots"]][[1]][[12]]$centroids_plot
```

#####  XLE

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_post[["plots"]][[1]][[13]]$centroids_plot
```

#####  XLF

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_post[["plots"]][[1]][[14]]$centroids_plot
```

#####  XLY

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_post[["plots"]][[1]][[15]]$centroids_plot
```

#####  XLI

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_post[["plots"]][[1]][[16]]$centroids_plot
```

#####  XLB

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_post[["plots"]][[1]][[17]]$centroids_plot
```



### Observation

The **forecast appears atypical, exhibiting a flat trajectory**. This suggests that the initial state may be problematic, potentially leading to a dead simulation and issues in the state transition process.


## 7.1 State Transition Problem

There are certain edge cases that may cause simulations as a straight line (stuck in a single state) or a dead state transition cycle (only between two states - back and forth) without any variability or exploring other states. We are naming this scenario as **State Transition Problem** and below are the cases that may lead to this issue.

- **Case 1: Absence Transitions:** This occurs when a state lacks any outgoing transitions to other states or itself. Once the simulation reaches such a state, it becomes stuck because there is no path forward, effectively halting the simulation in the same state.

- **Case 2: Self-State Only Transitions:** In this case, a state transitions exclusively to itself. When the simulation reaches such a state, it remains trapped in this state, unable to explore other states, causing stagnation.

- **Case 3: Cyclic Transitions:** This refers to a situation where states transition back and forth between each other in a closed loop. While the simulation remains active, it is constrained within the cycle, preventing the exploration of states outside the cycle.

We refer to the states that lead to any of these issues as **problematic states**. We are addressing the same solution approach for all the above three cases.


### Resolving the State Transition Problem

To resolve the State Transition Problem, we will conduct a **clustering analysis**. This involves grouping all states into *n* clusters by organizing states based on their proximity in the 2D space. This process will help identify nearby states to which a problematic state can potentially transition to. By enabling transitions to new states, this approach prevents the simulation from remaining stuck in a single state.

Below is the approach used to address the state transition problem:

#### Data and Clustering

- The first step in resolving the state transition problem is to group states into spatially coherent clusters based on their 2D centroid coordinates.  
- The `clustHVT` function from the HVT package is used for this purpose. It performs *Agglomerative Nesting (AGNES)* hierarchical clustering using the *Ward.D2* linkage method, which minimizes within-cluster variance and groups nearby states together.  
- Each resulting cluster represents a neighborhood of spatially close states that can serve as potential alternatives during simulation when a problematic state is encountered.  
- The function also provides useful visual outputs: dendrogram shows the hierarchical structure of the clustering and cluster heatmap visualizes inter-cluster relationships and proximities.  
- For more details on how `clustHVT` works, refer to the [HVT package documentation](https://cran.r-project.org/web/packages/HVT/HVT.pdf){target="_blank"}.


#### Handling Problematic States

- When a problematic state `S_p` is encountered, the algorithm identifies alternative transition options within the same cluster to allow the simulation to progress naturally.  
- Each state in the cluster, denoted as `S_k`, represents another possible state (neighbor) within the same spatial group as `S_p`. 
- **Steps:**
  1. Identify the cluster `C_j` to which the problematic state `S_p` belongs.  
  2. Within this cluster, compute the Euclidean distance between the problematic state `S_p` and every other neighboring state `S_k`:  
     \[
     d(S_p, S_k) = \sqrt{(x_p - x_k)^2 + (y_p - y_k)^2}
     \]
     where:  
     - `S_p` = current problematic state  
     - `S_k` = potential neighboring state within the same cluster  
     - `(x_p, y_p)` and `(x_k, y_k)` = centroid coordinates of the problematic and neighboring states
  3. Rank all neighboring states based on their distance from `S_p`.  
  4. Select the *n_nearest_neighbors* (user-defined, defaults to `n = 1`). These states serve as potential next states for transition.  
- This process ensures that the simulation can move from a problematic state to a nearby state within the same cluster, maintaining spatial continuity and allowing the simulation to evolve smoothly.


#### Probability-Based State Selection

- Once the `n` nearest neighboring states are identified to be more than 1, the next state is chosen using a probabilistic, proximity-driven approach.  
- This ensures that states closer to the problematic state `S_p` have a higher likelihood of being selected, while still introducing randomness to maintain natural simulation flow.  
- *Steps:*
  1. *Compute inverse-distance weights:* Each neighboring state `S_k` is assigned a weight inversely proportional to its distance from the problematic state `S_p`:  
     \[
     w_k = \frac{1}{d(S_p, S_k)}
     \]
     where:  
     - `w_k` = weight of neighbor `S_k`  
     - `d(S_p, S_k)` = Euclidean distance between `S_p` and `S_k`  

  2. *Normalize the weights:* Convert the weights into probabilities so that they sum to 1:  
     \[
     P_k = \frac{w_k}{\sum_{j=1}^{n} w_j}
     \]
     where `P_k` represents the probability of transitioning from `S_p` to neighbor `S_k`.  

  3. *Compute cumulative probabilities:* Generate cumulative probabilities to create transition intervals:  
     \[
     Cum_k = \sum_{i=1}^{k} P_i
     \]
     forming ranges like [0, Cum₁), [Cum₁, Cum₂), …, [Cumₙ₋₁, 1].  

  4. *Randomized state selection:* Draw a random number `r` from a *uniform distribution* of 0 to 1.
     \[
     r \sim U(0, 1)
     \]
     The next state `S_{next}` is chosen where:  
     \[
     Cum_{k-1} \le r < Cum_k
     \]
- This *inverse-distance weighted random selection* ensures that:  
  - Closer states have higher transition probabilities.  
  - The simulation transitions remain spatially coherent.  
  - Randomness prevents repetitive or deterministic state transitions, maintaining a realistic stochastic flow.


Let’s re-run the ex-post simulation with `handle_problematic_states = TRUE` to identify whether any states are problematic and understand the underlying cause with **6 clusters and 1 nearest neighbor**.


```{r, warning=FALSE, results='hide', message=FALSE}
ex_post <- msm(state_time_data = temporal_data_entire,
               forecast_type = "ex-post",
               transition_probability_matrix = prob_trans_matx,
               initial_state =  tail(temporal_data$Cell.ID, 1),
               num_simulations = 500,
               scoreHVT_results = scoring,
               trainHVT_results = hvt.results,
               actual_data = expost_forecasting,
               raw_dataset = entire_dataset,
               handle_problematic_states = TRUE,
               k = 6, n_nearest_neighbor = 1,
               mae_metric = "median",
               show_simulation = FALSE,
               time_column = "t")
```


```{r}
summary(ex_post)
```


According to the `msm` function summary, states **16** and **23** are identified as problematic. Let’s examine the transitions from these states to better understand the underlying issue.

```{r}
data <- prob_trans_matx[prob_trans_matx$Current_State == 16,]
datatable(data,rownames = FALSE)
```


```{r}
data <- prob_trans_matx[prob_trans_matx$Current_State == 23,]
datatable(data,rownames = FALSE)
```

From the tables above, states **16** and **23** show a combination of case 1 (self-transition) and case 3 (cyclic transition) behavior. State 23 transitions to itself as well as to 16, while state 16 transitions only to itself. Since the **initial state** in the ex-post simulation was **16**, the process remained in that state throughout, resulting in a flat simulation.

Although only state 16 was directly involved in this run, state 23 is also flagged because it transitions to self-state and a problematic state, which may again become stuck in a flat trajectory. Therefore, handling both states is important.


Below is the model dendrogram, where the 75 cells are grouped into an optimal **k = 6 clusters**. For each problematic state, **1 nearest neighbor** are identified, providing potential proximate states based on Euclidean distance to transition to when the simulation becomes stuck in a flat trajectory.

```{r,fig.align = "center",fig.width= 14, fig.height=5,out.width="100%"}
ex_post$dendrogram()
```



```{r, warning=FALSE,message=FALSE, fig.align = "center", fig.show ='hold', include=TRUE, results='asis', fig.width = 8, fig.height = 6.5, class.chunk='custom-heatmap-plot'}
ex_post$cluster_heatmap
```


With all problematic states now addressed, we can review the updated simulations, which no longer exhibit flatline behavior and instead show meaningful and more informative forecasts.

#### Ex-post plots after handling the problematic states {.tabset}

##### States

```{r, fig.width=8.5, out.width='100%',fig.height=6, fig.align='center'}
ex_post[["plots"]][[2]][[1]]
```




#####  CPI_Food

```{r, fig.width=8.5, out.width='100%',out.height='10%', fig.align='center'}
ex_post[["plots"]][[1]][[1]]$centroids_plot
```


#####  COIN

```{r, fig.width=8.5, out.width='100%',fig.height=6, fig.align='center'}
ex_post[["plots"]][[1]][[2]]$centroids_plot
```

#####  Copper_ETF

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_post[["plots"]][[1]][[3]]$centroids_plot
```

#####  SnP500_ETF

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_post[["plots"]][[1]][[4]]$centroids_plot
```

#####  Spot_Oil

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_post[["plots"]][[1]][[5]]$centroids_plot
```

#####  USD_Index

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_post[["plots"]][[1]][[6]]$centroids_plot
```


#####  Unemp_Rate

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_post[["plots"]][[1]][[7]]$centroids_plot
```

#####  Y10_Note

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_post[["plots"]][[1]][[8]]$centroids_plot
```

#####  Y2_Note

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_post[["plots"]][[1]][[9]]$centroids_plot
```

#####  Yield_Curve

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_post[["plots"]][[1]][[10]]$centroids_plot
```

#####  XLY

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_post[["plots"]][[1]][[11]]$centroids_plot
```

#####  XLP

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_post[["plots"]][[1]][[12]]$centroids_plot
```

#####  XLE

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_post[["plots"]][[1]][[13]]$centroids_plot
```

#####  XLF

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_post[["plots"]][[1]][[14]]$centroids_plot
```

#####  XLY

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_post[["plots"]][[1]][[15]]$centroids_plot
```

#####  XLI

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_post[["plots"]][[1]][[16]]$centroids_plot
```

#####  XLB

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_post[["plots"]][[1]][[17]]$centroids_plot
```

#### Observation

From the above plots, we can observe that the simulations are not confined to dead state causing flatline. This indicates that the simulations are not restricted to specific states but can explore beyond them, leading to a significant improvement in the forecast. The clustering analysis has successfully resolved the State Transition Problem, enabling the simulations to progress naturally and explore a wider range of states. This enhancement ensures the forecast is more reliable, capturing a broader spectrum of potential trends and patterns.

### MAE Table

Below is the MAE (Mean Absolute Error) values for each feature and state. It is calculated as the absolute difference between the actual and predicted median, providing insights into the model's accuracy and performance. The Mean MAE is calculated only from the features not states.

```{r}
mae_values_centroid <- sapply(ex_post[["plots"]][[1]], function(x) x[["mae"]])
mae_value_states <- ex_post[["plots"]][[2]][["mae"]]
mean_mae <- round(mean(mae_values_centroid),4)
mae_values <- c(mae_value_states,mae_values_centroid,mean_mae)
mae_values <- c(mae_value_states,mae_values_centroid,mean_mae)
plot_labels <- c(
  "States","CPI_Food",	"COIN",	"Copper_ETF",	"SnP500_ETF",	"Spot_Oil",	"USD_Index",	"Unemp_Rate",	"Y10_Note",	"Y2_Note",	"Yield_Curve",	"XLY",	"XLP",	"XLE",	"XLF",	"XLV",	"XLI"	,"XLB", "Mean of Variables' MAE")

data_1 <- data.frame(Plot = plot_labels,MAE = mae_values)
datatable(data_1, rownames = FALSE, options = list(pageLength = 19))
```


</br>

#### Ex-post plots with simulation lines {.tabset}

Let's look at the ex-post forecasting with the simulation lines after handling the problematic states.

```{r, warning=FALSE, message=FALSE,fig.align = "center", results='hide'}
ex_post <- msm(state_time_data = temporal_data_entire,
               forecast_type = "ex-post",
               transition_probability_matrix = prob_trans_matx,
               initial_state =  tail(temporal_data$Cell.ID, 1),
               num_simulations = 500,
               scoreHVT_results = scoring,
               trainHVT_results = hvt.results,
               actual_data = expost_forecasting,
               raw_dataset = entire_dataset,
               handle_problematic_states = TRUE,
               k = 6, n_nearest_neighbor = 1,
               mae_metric = "median",
               show_simulation = TRUE,
               time_column = "t")
```

##### States

```{r, fig.width=8.5, out.width='100%',fig.height=6, fig.align='center'}
ex_post[["plots"]][[2]][[1]]
```




#####  CPI_Food

```{r, fig.width=8.5, out.width='100%',out.height='10%', fig.align='center'}
ex_post[["plots"]][[1]][[1]]$centroids_plot
```


#####  COIN

```{r, fig.width=8.5, out.width='100%',fig.height=6, fig.align='center'}
ex_post[["plots"]][[1]][[2]]$centroids_plot
```

#####  Copper_ETF

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_post[["plots"]][[1]][[3]]$centroids_plot
```

#####  SnP500_ETF

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_post[["plots"]][[1]][[4]]$centroids_plot
```

#####  Spot_Oil

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_post[["plots"]][[1]][[5]]$centroids_plot
```

#####  USD_Index

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_post[["plots"]][[1]][[6]]$centroids_plot
```


#####  Unemp_Rate

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_post[["plots"]][[1]][[7]]$centroids_plot
```

#####  Y10_Note

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_post[["plots"]][[1]][[8]]$centroids_plot
```

#####  Y2_Note

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_post[["plots"]][[1]][[9]]$centroids_plot
```

#####  Yield_Curve

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_post[["plots"]][[1]][[10]]$centroids_plot
```

#####  XLY

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_post[["plots"]][[1]][[11]]$centroids_plot
```

#####  XLP

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_post[["plots"]][[1]][[12]]$centroids_plot
```

#####  XLE

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_post[["plots"]][[1]][[13]]$centroids_plot
```

#####  XLF

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_post[["plots"]][[1]][[14]]$centroids_plot
```

#####  XLY

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_post[["plots"]][[1]][[15]]$centroids_plot
```

#####  XLI

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_post[["plots"]][[1]][[16]]$centroids_plot
```

#####  XLB

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_post[["plots"]][[1]][[17]]$centroids_plot
```


# 8. Ex-ante Dynamic Forecasting

Now that ex-post is done, we now proceed with ex-ante Forecasting. In this section, we will predict the future states of the dataset using the `msm` - Monte Carlo Simulations of the Markov Chain. This process involves forecasting the states for the ex-ante period, enabling the identification of potential trends and patterns. 

**Ex-ante Period:**

- Transition Probability Matrix: 1999-12-01 to 2024-09-01

- Initial timestamp: 2025-09-01

- Initial state: 41

- Ex-ante Forecast: t+12 (2025-10-01 to 2026-09-01)

```{r warning=FALSE, results='hide'}
ex_ante_period <- seq.POSIXt(from = as.POSIXct("2025-10-01"),to = as.POSIXct("2026-09-01"),by = "1 month")
ex_ante_period <- as.POSIXct(format(ex_ante_period, "%Y-%m-%d"), tz = "")

ex_ante <- msm(state_time_data = temporal_data_entire,
               forecast_type = "ex-ante",
               transition_probability_matrix = prob_trans_matx,
               initial_state = tail(temporal_data_entire$Cell.ID, 1),
               n_ahead_ante = ex_ante_period,  
               num_simulations = 500,
               scoreHVT_results = scoring,
               trainHVT_results = hvt.results,
               raw_dataset = entire_dataset,
               handle_problematic_states = FALSE,
               mae_metric = "median",
               show_simulation= FALSE,
               time_column = "t")

```

### Ex-ante plots without simulation lines {.tabset}

##### States

```{r,fig.width=8.5, out.width='100%',fig.height=4.5, fig.align='center'}
ex_ante[["plots"]][["states_plots"]]
```


#####  CPI_Food

```{r, fig.width=8.5, out.width='100%',fig.height = 6, fig.align='center'}
ex_ante[["plots"]][["centroids_plot"]][[1]]
```


#####  COIN

```{r, fig.width=8.5, out.width='100%',fig.height=6, fig.align='center'}
ex_ante[["plots"]][["centroids_plot"]][[2]]
```

#####  Copper_ETF

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_ante[["plots"]][["centroids_plot"]][[3]]
```

#####  SnP500_ETF

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_ante[["plots"]][["centroids_plot"]][[4]]
```

#####  Spot_Oil

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_ante[["plots"]][["centroids_plot"]][[5]]
```

#####  USD_Index

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_ante[["plots"]][["centroids_plot"]][[6]]
```


#####  Unemp_Rate

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_ante[["plots"]][["centroids_plot"]][[7]]
```

#####  Y10_Note

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_ante[["plots"]][["centroids_plot"]][[8]]
```

#####  Y2_Note

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_ante[["plots"]][["centroids_plot"]][[9]]
```

#####  Yield_Curve

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_ante[["plots"]][["centroids_plot"]][[10]]
```

#####  XLY

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_ante[["plots"]][["centroids_plot"]][[11]]
```

#####  XLP

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_ante[["plots"]][["centroids_plot"]][[12]]
```

#####  XLE

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_ante[["plots"]][["centroids_plot"]][[13]]
```

#####  XLF

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_ante[["plots"]][["centroids_plot"]][[14]]
```

#####  XLY

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_ante[["plots"]][["centroids_plot"]][[15]]
```

#####  XLI

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_ante[["plots"]][["centroids_plot"]][[16]]
```

#####  XLB

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_ante[["plots"]][["centroids_plot"]][[17]]
```




### Ex-ante plots with simulation lines {.tabset}

```{r warning=FALSE, results='hide'}
ex_ante_period <- seq.POSIXt(from = as.POSIXct("2025-10-01"),to = as.POSIXct("2026-09-01"),by = "1 month")
ex_ante_period <- as.POSIXct(format(ex_ante_period, "%Y-%m-%d"), tz = "")

ex_ante <- msm(state_time_data = temporal_data_entire,
               forecast_type = "ex-ante",
               transition_probability_matrix = prob_trans_matx,
               initial_state = tail(temporal_data_entire$Cell.ID, 1),
               n_ahead_ante = ex_ante_period,  
               num_simulations = 500,
               scoreHVT_results = scoring,
               trainHVT_results = hvt.results,
               raw_dataset = entire_dataset,
               handle_problematic_states = FALSE,
               mae_metric = "median",
               show_simulation= TRUE,
               time_column = "t")
```

#### States

```{r,fig.width=8.5, out.width='100%',fig.height=4.5, fig.align='center'}
ex_ante[["plots"]][["states_plots"]]
```


####  CPI_Food

```{r, fig.width=8.5, out.width='100%',fig.height =6, fig.align='center'}
ex_ante[["plots"]][["centroids_plot"]][[1]]
```


#### COIN

```{r, fig.width=8.5, out.width='100%',fig.height=6, fig.align='center'}
ex_ante[["plots"]][["centroids_plot"]][[2]]
```

####  Copper_ETF

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_ante[["plots"]][["centroids_plot"]][[3]]
```

####  SnP500_ETF

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_ante[["plots"]][["centroids_plot"]][[4]]
```

####  Spot_Oil

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_ante[["plots"]][["centroids_plot"]][[5]]
```

####  USD_Index

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_ante[["plots"]][["centroids_plot"]][[6]]
```


####  Unemp_Rate

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_ante[["plots"]][["centroids_plot"]][[7]]
```

####  Y10_Note

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_ante[["plots"]][["centroids_plot"]][[8]]
```

####  Y2_Note

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_ante[["plots"]][["centroids_plot"]][[9]]
```

####  Yield_Curve

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_ante[["plots"]][["centroids_plot"]][[10]]
```

####  XLY

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_ante[["plots"]][["centroids_plot"]][[11]]
```

####  XLP

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_ante[["plots"]][["centroids_plot"]][[12]]
```

####  XLE

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_ante[["plots"]][["centroids_plot"]][[13]]
```

####  XLF

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_ante[["plots"]][["centroids_plot"]][[14]]
```

####  XLY

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_ante[["plots"]][["centroids_plot"]][[15]]
```

####  XLI

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_ante[["plots"]][["centroids_plot"]][[16]]
```

####  XLB

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_ante[["plots"]][["centroids_plot"]][[17]]
```


</br>


# 9. Ex-ante raw series forecasting

As the ex-post and ex-ante forecasting is completed, this section presents the visualization of the ex-ante raw series forecasting. While the HVT workflow uses log-differenced data, there also exists an untransformed raw dataset, which contains values in variables' original scale, with each measured in different units.

Introducing the new function `plotExAnteRawSeries` is designed to generate raw-series plots for each variable. When provided with both the untransformed and transformed datasets, along with a set of additional parameters, it produces the corresponding visualizations.

Below is the function signature along with detailed descriptions of all its arguments.

```{r plotExAnteRawSeries function, echo=TRUE, eval=FALSE}
plotExAnteRawSeries <- function(ex_ante_results,
                            original_dataset,
                            transformed_dataset,
                            time_column,
                            mae_metric = "median")
```


* __`ex_ante_results`__  -A list object produced from the ex-ante output of `msm`

* __`original_dataset`__ - A dataset in its raw form, before any log-difference transformation

* __`transformed_dataset`__ - A dataset that is transformed, i.e., after applying a log difference

* __`time_column`__ - A character string specifying the column name of the time stamp.

* __`mae_metric`__ - A character string specifying the selected mae metric.


Below is the logic behind this raw forecasting.

- For each period t+1, the forecast is generated by taking the raw, untransformed value from t–12 from the given dataset. This continues for the first 12 forecast points. From t+13 onward, the model switches to using the previous predicted value as the new raw input.

- In every step, whether the raw value is actual (first 12) or predicted (>12 n_ahead), it is multiplied by exponential of YoY(year-over-year) forecast for that period and metric to produce the final forecast.

- Example: For CPI_Food, the ex-ante forecast starts from 2025-10;

- Raw value at t–12 (2024-01): 321.67

- YoY forecast at 2025-10: 0.0389

- Raw forecast at t+1(2025-10): 321.67 × exp(0.0389) = 321.67 × 1.0397 = 334.44


```{r, warning = FALSE}
ex_ante_raw <- plotExAnteRawSeries(ex_ante_results = ex_ante,
                                   original_dataset = entire_dataset_raw,
                                   transformed_dataset = entire_dataset, 
                                   time_column = "t", mae_metric = "median" )
```

### Ex-ante raw forecast plots {.tabset}

####  CPI_Food

```{r, fig.width=8.5, out.width='100%',fig.height = 4.2, fig.align='center'}
ex_ante_raw[["plots"]]$CPI_Food
```


####  COIN

```{r, fig.width=8.5, out.width='100%',fig.height=6, fig.align='center'}
ex_ante_raw[["plots"]]$COIN
```

#### Copper_ETF

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_ante_raw[["plots"]]$Copper_ETF
```

####  SnP500_ETF

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_ante_raw[["plots"]]$SnP500_ETF
```

####  Spot_Oil

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_ante_raw[["plots"]]$Spot_Oil
```

####  USD_Index

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_ante_raw[["plots"]]$USD_Index
```


####  Unemp_Rate

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_ante_raw[["plots"]]$Unemp_Rate
```

####  Y10_Note

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_ante_raw[["plots"]]$Y10_Note
```

####  Y2_Note

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_ante_raw[["plots"]]$Y2_Note
```

####  Yield_Curve

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_ante_raw[["plots"]]$Yield_Curve
```

####  XLY

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_ante_raw[["plots"]]$XLY
```

####  XLP

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_ante_raw[["plots"]]$XLP
```

####  XLE

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_ante_raw[["plots"]]$XLE
```

####  XLF

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_ante_raw[["plots"]]$XLF
```

#### XLY

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_ante_raw[["plots"]]$XLY
```

####  XLI

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_ante_raw[["plots"]]$XLI
```

####  XLB

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_ante_raw[["plots"]]$XLB
```



### Ex-ante plots for n_ahead more than 12 {.tabset}


Now let's re-run the ex-ante forecasting for n_ahead more than 12 timestamps, to see how the model performs by selecting the base value from the predicted ex-ante raw.

```{r warning=FALSE, results='hide'}
ex_ante_period <- seq.POSIXt(from = as.POSIXct("2025-10-01"),to = as.POSIXct("2027-09-01"),by = "1 month")
ex_ante_period <- as.POSIXct(format(ex_ante_period, "%Y-%m-%d"), tz = "")

ex_ante <- msm(state_time_data = temporal_data_entire,
               forecast_type = "ex-ante",
               transition_probability_matrix = prob_trans_matx,
               initial_state = tail(temporal_data_entire$Cell.ID, 1),
               n_ahead_ante = ex_ante_period,  
               num_simulations = 500,
               scoreHVT_results = scoring,
               trainHVT_results = hvt.results,
               raw_dataset = entire_dataset,
               handle_problematic_states = FALSE,
               mae_metric = "median",
               show_simulation= TRUE,
               time_column = "t")
```

#### States

```{r,fig.width=8.5, out.width='100%',fig.height=4.5, fig.align='center'}
ex_ante[["plots"]][["states_plots"]]
```


####  CPI_Food

```{r, fig.width=8.5, out.width='100%',fig.height =6, fig.align='center'}
ex_ante[["plots"]][["centroids_plot"]][[1]]
```


#### COIN

```{r, fig.width=8.5, out.width='100%',fig.height=6, fig.align='center'}
ex_ante[["plots"]][["centroids_plot"]][[2]]
```

####  Copper_ETF

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_ante[["plots"]][["centroids_plot"]][[3]]
```

####  SnP500_ETF

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_ante[["plots"]][["centroids_plot"]][[4]]
```

####  Spot_Oil

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_ante[["plots"]][["centroids_plot"]][[5]]
```

####  USD_Index

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_ante[["plots"]][["centroids_plot"]][[6]]
```


####  Unemp_Rate

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_ante[["plots"]][["centroids_plot"]][[7]]
```

####  Y10_Note

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_ante[["plots"]][["centroids_plot"]][[8]]
```

####  Y2_Note

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_ante[["plots"]][["centroids_plot"]][[9]]
```

####  Yield_Curve

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_ante[["plots"]][["centroids_plot"]][[10]]
```

####  XLY

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_ante[["plots"]][["centroids_plot"]][[11]]
```

####  XLP

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_ante[["plots"]][["centroids_plot"]][[12]]
```

####  XLE

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_ante[["plots"]][["centroids_plot"]][[13]]
```

####  XLF

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_ante[["plots"]][["centroids_plot"]][[14]]
```

####  XLY

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_ante[["plots"]][["centroids_plot"]][[15]]
```

####  XLI

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_ante[["plots"]][["centroids_plot"]][[16]]
```

####  XLB

```{r, fig.width=8.5,out.width='100%', fig.height=6, fig.align='center'}
ex_ante[["plots"]][["centroids_plot"]][[17]]
```


### Ex-ante raw series plots for n_ahead more than 12 {.tabset}

```{r, warning = FALSE}
ex_ante_raw <- plotExAnteRawSeries(ex_ante_results = ex_ante,
                                   original_dataset = entire_dataset_raw,
                                   transformed_dataset = entire_dataset, 
                                   time_column = "t", mae_metric = "median" )
```

####  CPI_Food

```{r, fig.width=10, out.width='100%',fig.height = 4.2, fig.align='center'}
ex_ante_raw[["plots"]]$CPI_Food
```


####  COIN

```{r, fig.width=10, out.width='100%',fig.height=4.2, fig.align='center'}
ex_ante_raw[["plots"]]$COIN
```

#### Copper_ETF

```{r, fig.width=10,out.width='100%', fig.height=4.2, fig.align='center'}
ex_ante_raw[["plots"]]$Copper_ETF
```

####  SnP500_ETF

```{r, fig.width=10,out.width='100%', fig.height=4.2, fig.align='center'}
ex_ante_raw[["plots"]]$SnP500_ETF
```

####  Spot_Oil

```{r, fig.width=10,out.width='100%', fig.height=4.2, fig.align='center'}
ex_ante_raw[["plots"]]$Spot_Oil
```

####  USD_Index

```{r, fig.width=10,out.width='100%', fig.height=4.2, fig.align='center'}
ex_ante_raw[["plots"]]$USD_Index
```


####  Unemp_Rate

```{r, fig.width=10,out.width='100%', fig.height=4.2, fig.align='center'}
ex_ante_raw[["plots"]]$Unemp_Rate
```

####  Y10_Note

```{r, fig.width=10,out.width='100%', fig.height=4.2, fig.align='center'}
ex_ante_raw[["plots"]]$Y10_Note
```

####  Y2_Note

```{r, fig.width=10,out.width='100%', fig.height=4.2, fig.align='center'}
ex_ante_raw[["plots"]]$Y2_Note
```

####  Yield_Curve

```{r, fig.width=10,out.width='100%', fig.height=4.2, fig.align='center'}
ex_ante_raw[["plots"]]$Yield_Curve
```

####  XLY

```{r, fig.width=10,out.width='100%', fig.height=4.2, fig.align='center'}
ex_ante_raw[["plots"]]$XLY
```

####  XLP

```{r, fig.width=10,out.width='100%', fig.height=4.2, fig.align='center'}
ex_ante_raw[["plots"]]$XLP
```

####  XLE

```{r, fig.width=10,out.width='100%', fig.height=4.2, fig.align='center'}
ex_ante_raw[["plots"]]$XLE
```

####  XLF

```{r, fig.width=10,out.width='100%', fig.height=4.2, fig.align='center'}
ex_ante_raw[["plots"]]$XLF
```

#### XLY

```{r, fig.width=10,out.width='100%', fig.height=4.2, fig.align='center'}
ex_ante_raw[["plots"]]$XLY
```

####  XLI

```{r, fig.width=10,out.width='100%', fig.height=4.2, fig.align='center'}
ex_ante_raw[["plots"]]$XLI
```

####  XLB

```{r, fig.width=10,out.width='100%', fig.height=4.2, fig.align='center'}
ex_ante_raw[["plots"]]$XLB
```


# 10. Summary

This notebook demonstrated the application of the HVT package for dynamic macroeconomic time series forecasting, encompassing data preprocessing, HVT model construction, hierarchical visualization, scoring, and forecasting using Monte Carlo Simulations of Markov Chains (MSM).  

### Key Insights:  

1. **Efficient Data Compression and Visualization**:  
   The HVT model achieved compression ratio while retaining critical data structures, enabling the creation of intuitive and interpretable visualizations that captured macroeconomic patterns effectively.  

2. **Challenges in Forecasting**:  
   The forecasting process encountered common issues such as self-state stagnation, absence of transitions, and cyclic state patterns. These problems hindered accurate state evolution, leading to unrealistic or static predictions.  

The HVT package, with its use of `msm` techniques, has shown to be a useful tool for addressing forecasting challenges and analyzing trends. Adjusting the parameters further could help improve clustering strategies and explore additional applications to enhance performance and forecasting accuracy.






